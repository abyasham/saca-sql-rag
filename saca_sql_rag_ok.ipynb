{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Network Packet Security Analysis Chatbot using SQL RAG Approach and a Cybersecurity-Tuned LLM**"
      ],
      "metadata": {
        "id": "8xbVGA2LRNr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Overview**\n",
        "This project provides an advanced framework for cybersecurity threat analysis through a conversational interface. It empowers security analysts to investigate network traffic data by asking questions in natural language.\n",
        "\n",
        "The core of this system is segolilylabs/Lily-Cybersecurity-7B-v0.2, a Large Language Model (LLM) specifically fine-tuned for the cybersecurity domain. This specialization allows it to understand the nuances of network protocols, attack patterns, and security-specific terminology, leading to more accurate and relevant analysis.\n",
        "\n",
        "The framework's main feature is a dual-analysis engine that enables analysts to investigate data using two complementary methods: a Text-to-SQL approach for database-wide queries and a RAG-like approach for deep, context-specific analysis.\n",
        "\n",
        "# **2. Cybersecurity-Centric Architecture**\n",
        "The project's architecture is designed to support a typical security analysis workflow, from raw data ingestion to actionable insights. The workflow  explicitly evaluate the two distinct analysis modes derived from from `bizbot.py`: **SQL Data Query** and **AI Security Analysis (RAG)** used in an attack sample of network traffic capture. The final output is a clear Ragas score for each mode, allowing for a direct performance comparison.\n",
        "\n",
        "**Key Components:**\n",
        "*   pcap2csv-ok.py: A utility that parses raw packet captures (.pcap) and extracts a curated set of security-relevant features into a CSV file, creating a structured dataset ready for investigation.\n",
        "*   Segolily LLM (The AI Analyst): The core of the system. As a cybersecurity-tuned LLM, it excels at: Generating precise SQL queries for threat hunting in network logs, Understanding security context to analyze specific events (e.g., a single anomalous connection), Recognizing security-related entities like IP addresses, port numbers, and attack types.\n",
        "*   Chatbot Application (bizbot.py): The primary interface for the security analyst. Built with Streamlit, it manages data loading and provides access to the dual-analysis engine.\n",
        "\n",
        "You can create a new Colab notebook and copy-paste the content of each cell.\n",
        "\n",
        "### **Colab Notebook: Evaluating BizBot's SQL and AI Analysis Modes**\n",
        "\n",
        "---\n",
        "\n",
        "### **Part 0: Introduction and Setup**\n",
        "\n",
        "#### **Cell 1: Introduction (Markdown)**\n",
        "# Colab Notebook:\n",
        "\n",
        "This notebook evaluates two core analysis methodologies inspired by the `bizbot.py` script, using the `segolily/Lily-Cybersecurity-7B` model for all AI tasks.\n",
        "\n",
        "1.  **SQL Data Query Mode**: This section simulates BizBot's Text-to-SQL functionality. We test the LLM's ability to convert a natural language question into an executable SQL query. The evaluation measures if the final answer derived from the query is correct.\n",
        "\n",
        "2.  **AI Security Analysis (RAG) Mode**: This section simulates BizBot's RAG (Retrieval-Augmented Generation) functionality. In a real RAG system, a retriever would first find relevant information (e.g., specific rows in the CSV). We simulate the final, crucial step: providing this retrieved context to the LLM and testing its ability to accurately answer a question based *only* on that context.\n",
        "\n",
        "The final output provides a `ragas` score for each mode, allowing for a direct comparison of their accuracy.\n",
        "\n",
        "**Runtime Requirement**: A GPU is required. In Colab, go to `Runtime > Change runtime time` and select at least `T4 GPU`.\n"
      ],
      "metadata": {
        "id": "diYbuYYRiicm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Cell 2: Install Dependencies**"
      ],
      "metadata": {
        "id": "05ZtwHog85Fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install all required libraries\n",
        "!pip install -q pandas pandasql\n",
        "!pip install -q transformers accelerate\n",
        "!pip install -q datasets langchain ragas\n",
        "!pip install -q langchain-openai # Install the OpenAI integration for Langchain/Ragas"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pandasql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "ysDS5Otkiicn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69fef641-f964-410e-998b-8bcd7284bae5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Part 1: Model and Data Preparation**\n",
        "\n",
        "#### **Cell 3: Load LLM and Tokenizer**"
      ],
      "metadata": {
        "id": "FvSRyWUxiicp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the latest version of bitsandbytes is installed just before use\n",
        "!pip install -U -q bitsandbytes\n",
        "\n",
        "# Add a simple check to confirm bitsandbytes is available\n",
        "try:\n",
        "    import bitsandbytes as bnb\n",
        "    print(\"bitsandbytes installed successfully.\")\n",
        "except ImportError:\n",
        "    # If this still fails, there's a deeper environment issue or conflict\n",
        "    print(\"Error: bitsandbytes not found after installation.\")\n",
        "    # You might consider restarting the runtime if this happens\n",
        "    # get_ipython().kernel.do_shutdown(True) # Uncomment to force restart\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "\n",
        "# The user-specified model for all analysis tasks\n",
        "model_name = \"segolilylabs/Lily-Cybersecurity-7B-v0.2\"\n",
        "\n",
        "# Use 4-bit quantization to load the 7B model on a Colab GPU\n",
        "# This requires the bitsandbytes library\n",
        "# Define quantization_config only if bitsandbytes is available\n",
        "if 'bnb' in globals() and bnb:\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "    )\n",
        "\n",
        "    print(\"Loading model and tokenizer... (This may take a few minutes)\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    # Only attempt to load with quantization if bitsandbytes is available\n",
        "    try:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            quantization_config=quantization_config,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\", # Automatically use the GPU\n",
        "        )\n",
        "\n",
        "        # Create a transformers pipeline for easier text generation\n",
        "        hf_pipeline = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=150,\n",
        "            temperature=0.01, # Set low for factual, deterministic outputs\n",
        "        )\n",
        "        print(\"Model loaded successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during model loading: {e}\")\n",
        "        print(\"Please ensure you have a GPU runtime enabled (Runtime -> Change runtime type -> T4 GPU).\")\n",
        "        print(\"If using a GPU, consider restarting the Colab runtime (Runtime -> Restart runtime) and trying again.\")\n",
        "else:\n",
        "    print(\"bitsandbytes is not available. Cannot load model with 4-bit quantization.\")\n",
        "    print(\"Ensure you have a GPU runtime enabled and bitsandbytes installs correctly.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bitsandbytes installed successfully.\n",
            "Loading model and tokenizer... (This may take a few minutes)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c053ff24b20a4aca9b51bba5b2f43e87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "JvOGLTWQiicp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "c053ff24b20a4aca9b51bba5b2f43e87",
            "6e524c8cf87244ffaa1dc811572ef4dd",
            "30bbe46bc9c74c01a92eff532ce01b4a",
            "8826fe63e89645f79ed0892e84df6b41",
            "42c9090cefca45cea571855536c2dfd9",
            "31b9aed3f791419c9a7d8b0e51e3c09e",
            "497cacbfaac84b1ab5c07bce41330b63",
            "f8d7394699494ec4a8c40d0dbb3e730c",
            "6393048a02a8421a8d7b36d13a8a9d15",
            "8261d8aa782c4e069faf411086ed0598",
            "b2a0053c05ea43c1b4b933d8dabf70f5"
          ]
        },
        "outputId": "745765f1-a34c-4cb4-f2e5-600d68c9108f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Cell 4: Cybersecurity LLM generated answer**\n",
        "This function takes a natural language question and the schema (column names) of a Pandas DataFrame as input. Its goal is to use the loaded Large Language Model (LLM), in this case the [Segolily-Cybersecurity-7b](https://huggingface.co/segolilylabs/Lily-Cybersecurity-7B-v0.2) to convert the question into a SQL query and then run that query against the DataFrame to get an answer."
      ],
      "metadata": {
        "id": "We_i6P3SLNba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'hf_pipeline' in globals() and 'pysqldf' in globals() and 'df' in globals():\n",
        "    def text_to_sql_and_execute(natural_language_question, dataframe_schema):\n",
        "        \"\"\"\n",
        "        Uses the Segolily LLM (hf_pipeline) to convert a natural language question\n",
        "        into a SQL query, then executes the query against the dataframe.\n",
        "        \"\"\"\n",
        "        # 1. Craft a prompt for the Segolily LLM to generate SQL\n",
        "        # Provide the dataframe schema so the LLM knows the table name ('df') and column names\n",
        "        # You might need to experiment with the prompt structure for best results with your LLM\n",
        "        prompt_for_sql_generation = f\"\"\"\n",
        "You are a helpful assistant that translates natural language questions into SQL queries for a pandas DataFrame named 'df'.\n",
        "The DataFrame 'df' has the following columns: {dataframe_schema}.\n",
        "Generate a concise SQL query that answers the following question based on the 'df' DataFrame.\n",
        "Only return the SQL query and nothing else.\n",
        "\n",
        "Question: {natural_language_question}\n",
        "\n",
        "SQL Query:\n",
        "\"\"\"\n",
        "\n",
        "        # 2. Use the Segolily LLM (hf_pipeline) to generate the SQL query\n",
        "        # Adjust parameters like max_new_tokens and stop_sequence if needed\n",
        "        # Set stop_sequence to prevent the LLM from generating extra text after the query\n",
        "        try:\n",
        "            sql_generation_response = hf_pipeline(\n",
        "                prompt_for_sql_generation,\n",
        "                max_new_tokens=100, # Adjust based on expected query length\n",
        "                do_sample=False, # Aim for deterministic output\n",
        "                pad_token_id=hf_pipeline.tokenizer.eos_token_id # Needed for some models\n",
        "                # Add other parameters as needed by your pipeline/model\n",
        "            )[0]['generated_text']\n",
        "\n",
        "            # Extract the generated SQL query from the response\n",
        "            # This parsing might need adjustment based on how the LLM formats its output\n",
        "            # Assuming the LLM output starts with \"SQL Query:\" and we want everything after it\n",
        "            generated_sql = sql_generation_response.split(\"SQL Query:\")[-1].strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during LLM SQL generation for question '{natural_language_question}': {e}\")\n",
        "            generated_sql = \"SELECT 'Error: LLM failed to generate SQL';\" # Default to an error query for robustness\n",
        "\n",
        "        # 3. Execute the generated SQL query using pysqldf\n",
        "        model_answer_string = \"Error: Could not execute SQL.\"\n",
        "        try:\n",
        "            # IMPORTANT: Check if the generated_sql is not empty or an error string before executing\n",
        "            if generated_sql and not generated_sql.startswith(\"SELECT 'Error:\") and generated_sql.lower().strip().startswith(\"select\"):\n",
        "                 # Some basic validation to ensure it looks like a SELECT query\n",
        "                 model_answer_df = pysqldf(generated_sql)\n",
        "                 # Convert the result DataFrame to a string for comparison\n",
        "                 model_answer_string = model_answer_df.to_string(index=False)\n",
        "            else:\n",
        "                 model_answer_string = \"Error: LLM generated invalid or empty SQL.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error executing LLM-generated SQL query: {generated_sql} - Error: {e}\")\n",
        "            model_answer_string = f\"Error executing LLM-generated SQL: {e}\"\n",
        "\n",
        "\n",
        "        # 4. Return the generated answer string, the generated SQL, and potentially the raw LLM response\n",
        "        return model_answer_string, generated_sql, sql_generation_response\n",
        "    print(\"text_to_sql_and_execute function defined successfully.\")\n",
        "else:\n",
        "    print(\"Dependencies (hf_pipeline, pysqldf, df) not available. Cannot define text_to-sql_and_execute function.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbzTwi4qLEbr",
        "outputId": "39b59e0f-efeb-43d2-cab8-0b44f29967fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_to_sql_and_execute function defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Cell 4: Load and Prepare the ToN-IoT Dataset as a \"Database\"**\n",
        "The TON_IoT datasets are new generations of Industry 4.0/Internet of Things (IoT) and Industrial IoT (IIoT) datasets for evaluating the fidelity and efficiency of different cybersecurity applications based on Artificial Intelligence (AI). The datasets have been called 'ToN_IoT' as they include heterogeneous data sources collected from Telemetry datasets of IoT and IIoT sensors, Operating systems datasets of Windows 7 and 10 as well as Ubuntu 14 and 18 TLS and Network traffic datasets. The testbed was deployed using multiple virtual machines and hosts of windows, Linux and Kali operating systems to manage the interconnection between the three layers of IoT, Cloud and Edge/Fog systems. Various attacking techniques, such as DoS, DDoS and ransomware, against web applications, IoT gateways and computer systems across the IoT/IIoT network.  The datasets were gathered in a parallel processing to collect several normal and cyber-attack events from network traffic, Windows audit traces, Linux audit traces, and telemetry data of IoT services. The datasets can be found here https://research.unsw.edu.au/projects/toniot-datasets"
      ],
      "metadata": {
        "id": "rQUjXNPSiicq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyJ6gwD172vX",
        "outputId": "d9a4deeb-d84a-4138-b371-1611621ddd68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pandasql import sqldf\n",
        "\n",
        "# Define the path to your CSV file in Google Drive\n",
        "# IMPORTANT: Replace 'Your_Folder_Name' with the actual path to your folder in Drive\n",
        "# Example: If the file is in a folder named 'iot_data' directly in your Drive's root,\n",
        "# the path might be '/content/drive/MyDrive/iot_data/ML-EdgeIIoT-dataset.csv'\n",
        "# If it's in 'My Drive/Colab Notebooks/data/ML-EdgeIIoT-dataset.csv', the path is\n",
        "# '/content/drive/MyDrive/Colab Notebooks/data/ML-EdgeIIoT-dataset.csv'\n",
        "\n",
        "# !!! REPLACE THIS WITH YOUR ACTUAL FILE PATH IN GOOGLE DRIVE !!!\n",
        "LABELED_CSV_FILE = '/content/.../sampled_toniot_dataset.csv'\n",
        "\n",
        "print(f\"Attempting to load dataset from Google Drive: {LABELED_CSV_FILE}\")\n",
        "\n",
        "# Check if the file exists before trying to load\n",
        "if not os.path.exists(LABELED_CSV_FILE):\n",
        "    print(f\"Error: File not found at '{LABELED_CSV_FILE}'\")\n",
        "    print(\"Please double-check the path in Google Drive.\")\n",
        "    print(\"Make sure Google Drive is mounted and the path copied from the Colab file explorer is correct.\")\n",
        "    # You might want to stop execution here if the file isn't found\n",
        "    # raise FileNotFoundError(f\"Dataset not found at {LABELED_CSV_FILE}\")\n",
        "else:\n",
        "    print(\"File found. Loading into pandas DataFrame...\")\n",
        "    # Load the data into a pandas DataFrame\n",
        "    # Use appropriate encoding if necessary (e.g., encoding='latin1')\n",
        "    try:\n",
        "        # It's common for IoT datasets to have encoding issues, try 'latin1' or others if utf-8 fails\n",
        "        try:\n",
        "            df = pd.read_csv(LABELED_CSV_FILE)\n",
        "        except UnicodeDecodeError:\n",
        "            print(\"UTF-8 decode failed, trying latin1 encoding...\")\n",
        "            df = pd.read_csv(LABELED_CSV_FILE, encoding='latin1')\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred while reading the CSV: {e}\")\n",
        "            # Re-raise the exception if it's not a decoding issue we handled\n",
        "            raise e\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "         print(f\"Error: File not found at '{LABELED_CSV_FILE}'. Please ensure the path is correct.\")\n",
        "         # Handle or re-raise the error as appropriate\n",
        "         # raise\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the CSV file: {e}\")\n",
        "        print(\"Please check the file format and content.\")\n",
        "        # Handle or re-raise the error as appropriate\n",
        "        # raise\n",
        "\n",
        "\n",
        "    # IMPORTANT: Clean column names to be SQL-friendly (replace dots and spaces/special chars)\n",
        "    # Also handle potential leading/trailing whitespace in column names\n",
        "    df.columns = df.columns.str.strip().str.replace('[^a-zA-Z0-9_]', '_', regex=True)\n",
        "\n",
        "    # This function allows us to query the pandas DataFrame using SQL syntax\n",
        "    pysqldf = lambda q: sqldf(q, globals())\n",
        "\n",
        "    print(\"Data loaded. Columns are now SQL-friendly.\")\n",
        "    print(\"\\n--- DataFrame Head ---\")\n",
        "    display(df.head()) # Use display instead of print for better formatting in Colab\n",
        "\n",
        "    # Optional: Print info about the dataframe to verify\n",
        "    print(\"\\n--- DataFrame Info ---\")\n",
        "    df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load dataset from Google Drive: /content/drive/MyDrive/PHDS/experiment/bizbot-segolily/toniot-dataset/sampled_toniot_dataset.csv\n",
            "File found. Loading into pandas DataFrame...\n",
            "Data loaded. Columns are now SQL-friendly.\n",
            "\n",
            "--- DataFrame Head ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          src_ip  src_port        dst_ip  dst_port proto service  duration  \\\n",
              "0  192.168.1.193     49739  192.168.1.33        80   tcp       -  0.000018   \n",
              "1  192.168.1.193     49401  192.168.1.37      8080   tcp       -  0.000138   \n",
              "2  192.168.1.193     49663  192.168.1.33        80   tcp       -  0.000022   \n",
              "3  192.168.1.193     49345  192.168.1.37      8080   tcp       -  0.000009   \n",
              "4  192.168.1.193     49875  192.168.1.37      8080   tcp       -  0.000142   \n",
              "\n",
              "   src_bytes  dst_bytes conn_state  ...  dst_ip_bytes  dns_query  \\\n",
              "0          0          0        REJ  ...            40          -   \n",
              "1          0          0        REJ  ...            40          -   \n",
              "2          0          0        REJ  ...            40          -   \n",
              "3          0          0        REJ  ...            40          -   \n",
              "4          0          0        REJ  ...            40          -   \n",
              "\n",
              "   dns_rejected  ssl_version  ssl_cipher http_method http_uri http_version  \\\n",
              "0             -            -           -           -        -            -   \n",
              "1             -            -           -           -        -            -   \n",
              "2             -            -           -           -        -            -   \n",
              "3             -            -           -           -        -            -   \n",
              "4             -            -           -           -        -            -   \n",
              "\n",
              "  label      type  \n",
              "0     1  backdoor  \n",
              "1     1  backdoor  \n",
              "2     1  backdoor  \n",
              "3     1  backdoor  \n",
              "4     1  backdoor  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d526e13-f8ae-4bff-b194-2db9117fe220\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src_ip</th>\n",
              "      <th>src_port</th>\n",
              "      <th>dst_ip</th>\n",
              "      <th>dst_port</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>conn_state</th>\n",
              "      <th>...</th>\n",
              "      <th>dst_ip_bytes</th>\n",
              "      <th>dns_query</th>\n",
              "      <th>dns_rejected</th>\n",
              "      <th>ssl_version</th>\n",
              "      <th>ssl_cipher</th>\n",
              "      <th>http_method</th>\n",
              "      <th>http_uri</th>\n",
              "      <th>http_version</th>\n",
              "      <th>label</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>192.168.1.193</td>\n",
              "      <td>49739</td>\n",
              "      <td>192.168.1.33</td>\n",
              "      <td>80</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>REJ</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "      <td>backdoor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>192.168.1.193</td>\n",
              "      <td>49401</td>\n",
              "      <td>192.168.1.37</td>\n",
              "      <td>8080</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>REJ</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "      <td>backdoor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>192.168.1.193</td>\n",
              "      <td>49663</td>\n",
              "      <td>192.168.1.33</td>\n",
              "      <td>80</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>REJ</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "      <td>backdoor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>192.168.1.193</td>\n",
              "      <td>49345</td>\n",
              "      <td>192.168.1.37</td>\n",
              "      <td>8080</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>REJ</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "      <td>backdoor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>192.168.1.193</td>\n",
              "      <td>49875</td>\n",
              "      <td>192.168.1.37</td>\n",
              "      <td>8080</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>REJ</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "      <td>backdoor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d526e13-f8ae-4bff-b194-2db9117fe220')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d526e13-f8ae-4bff-b194-2db9117fe220 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d526e13-f8ae-4bff-b194-2db9117fe220');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9dd1d4b5-994a-4c0a-bfa8-b4c8e5888b42\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9dd1d4b5-994a-4c0a-bfa8-b4c8e5888b42')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9dd1d4b5-994a-4c0a-bfa8-b4c8e5888b42 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- DataFrame Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 24 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   src_ip        1000 non-null   object \n",
            " 1   src_port      1000 non-null   int64  \n",
            " 2   dst_ip        1000 non-null   object \n",
            " 3   dst_port      1000 non-null   int64  \n",
            " 4   proto         1000 non-null   object \n",
            " 5   service       1000 non-null   object \n",
            " 6   duration      1000 non-null   float64\n",
            " 7   src_bytes     1000 non-null   int64  \n",
            " 8   dst_bytes     1000 non-null   int64  \n",
            " 9   conn_state    1000 non-null   object \n",
            " 10  missed_bytes  1000 non-null   int64  \n",
            " 11  src_pkts      1000 non-null   int64  \n",
            " 12  src_ip_bytes  1000 non-null   int64  \n",
            " 13  dst_pkts      1000 non-null   int64  \n",
            " 14  dst_ip_bytes  1000 non-null   int64  \n",
            " 15  dns_query     1000 non-null   object \n",
            " 16  dns_rejected  1000 non-null   object \n",
            " 17  ssl_version   1000 non-null   object \n",
            " 18  ssl_cipher    1000 non-null   object \n",
            " 19  http_method   1000 non-null   object \n",
            " 20  http_uri      1000 non-null   object \n",
            " 21  http_version  1000 non-null   object \n",
            " 22  label         1000 non-null   int64  \n",
            " 23  type          1000 non-null   object \n",
            "dtypes: float64(1), int64(10), object(13)\n",
            "memory usage: 187.6+ KB\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "h_IN8GX1iicr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "outputId": "747b92a6-4187-474f-8465-302ea3b2dd12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'df' in globals():\n",
        "        print(df['type'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYelk93T7eEJ",
        "outputId": "0c55be64-de29-46f3-ad86-8420b048525d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['backdoor' 'ddos' 'dos' 'injection' 'mitm' 'normal' 'password'\n",
            " 'ransomware' 'scanning' 'xss']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'df' in globals():\n",
        "    print(\"Columns in the dataset:\")\n",
        "    print(df.columns.tolist())\n",
        "else:\n",
        "    print(\"DataFrame 'df' not found. Please ensure Cell 4 ran successfully and the dataset was loaded correctly.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96v52KhOM83S",
        "outputId": "f4b96c8c-4491-4ce2-8f7b-e3745d38a1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the dataset:\n",
            "['src_ip', 'src_port', 'dst_ip', 'dst_port', 'proto', 'service', 'duration', 'src_bytes', 'dst_bytes', 'conn_state', 'missed_bytes', 'src_pkts', 'src_ip_bytes', 'dst_pkts', 'dst_ip_bytes', 'dns_query', 'dns_rejected', 'ssl_version', 'ssl_cipher', 'http_method', 'http_uri', 'http_version', 'label', 'type']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Part 2: SQL Data Query Mode Evaluation**\n",
        "\n",
        "#### **Cell 5: Define and Simulate the SQL Mode Process**"
      ],
      "metadata": {
        "id": "vyDIB9fUiicr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure df and pysqldf are available from previous cells\n",
        "if 'df' in globals() and 'pysqldf' in globals():\n",
        "    query_to_get_ddos_count = \"SELECT DISTINCT src_ip FROM df WHERE type = 'mitm';\"\n",
        "    try:\n",
        "        actual_ddos_count_df = pysqldf(query_to_get_ddos_count)\n",
        "        # Convert the result DataFrame to a string, without the index\n",
        "        actual_ddos_count_string = actual_ddos_count_df.to_string(index=False)\n",
        "        print(\"What are the source IP addresses involved in 'MITM' attacks? Show only unique IPs.\")\n",
        "        print(actual_ddos_count_string)\n",
        "    except Exception as e:\n",
        "        print(f\"Error executing SQL query: {e}\")\n",
        "else:\n",
        "    print(\"DataFrame 'df' or function 'pysqldf' not found. Please run Cell 4.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6xKs8aKrvUx",
        "outputId": "8a57161c-6e0c-4adc-9277-3bdf1cd6cbaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are the source IP addresses involved in 'MITM' attacks? Show only unique IPs.\n",
            "       src_ip\n",
            " 192.168.1.34\n",
            " 192.168.1.31\n",
            "192.168.1.152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import random\n",
        "import pandas as pd\n",
        "from pandasql import sqldf\n",
        "\n",
        "# Ensure the DataFrame 'df' and the function 'pysqldf' are available from Cell 4\n",
        "# If not, you would need to re-run Cell 4 or ensure they are in the global scope.\n",
        "\n",
        "# --- IMPORTANT: Define questions and the *correct* SQL queries to get the ground truth ---\n",
        "# You MUST define the correct SQL query for each question here.\n",
        "# These queries will be executed to get the ground truth.\n",
        "# Use the 'type' column for specific attack names (e.g., 'ddos', 'normal', 'mitm')\n",
        "# Use the 'label' column only if querying the binary label (0 or 1)\n",
        "\n",
        "sql_eval_data_with_queries = [\n",
        "    {\n",
        "        \"question\": \"How many connections are classified as 'backdoor' attacks?\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE type = 'backdoor';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How many connections are classified as 'ddos' attacks?\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE type = 'ddos';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the source IP addresses involved in 'mitm' attacks? Show only unique IPs.\",\n",
        "        \"ground_truth_query\": \"SELECT DISTINCT src_ip FROM df WHERE type = 'mitm';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Count the total number of unique destination IP addresses that experienced attacks (where the binary label is 1).\",\n",
        "        # Query uses the 'label' column for binary classification 1 (attack)\n",
        "        \"ground_truth_query\": \"SELECT COUNT(DISTINCT dst_ip) FROM df WHERE label = 1;\"\n",
        "    },\n",
        "     {\n",
        "        \"question\": \"What is the average duration of 'dos' attacks?\",\n",
        "        \"ground_truth_query\": \"SELECT AVG(duration) FROM df WHERE type = 'dos';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"List the unique protocols used in 'injection' attacks.\", # Changed 'sql_injection' to 'injection' based on unique values\n",
        "        \"ground_truth_query\": \"SELECT DISTINCT proto FROM df WHERE type = 'injection';\" # Changed 'sql_injection' to 'injection'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Count the number of connections for each traffic type (exclude 'normal').\", # Changed 'attack type' and 'Benign' to 'traffic type' and 'normal'\n",
        "        \"ground_truth_query\": \"SELECT type, COUNT(*) FROM df WHERE type != 'normal' GROUP BY type;\" # Changed 'benign' to 'normal'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Find connections that are 'ddos' attacks with a duration greater than 10 seconds.\",\n",
        "        \"ground_truth_query\": \"SELECT * FROM df WHERE type = 'ddos' AND duration > 10;\"\n",
        "    },\n",
        "    # Removed question about 'maliciousactivity' as it's not in unique types\n",
        "    # {\n",
        "    #     \"question\": \"What is the maximum number of packets sent in a connection labeled as 'maliciousactivity'?\",\n",
        "    #     \"ground_truth_query\": \"SELECT MAX(src_pkts + dst_pkts) FROM df WHERE type = 'maliciousactivity';\"\n",
        "    # },\n",
        "    {\n",
        "        \"question\": \"List the destination ports that are commonly targeted by 'scanning' attacks. Show unique ports.\", # Changed 'portscan' to 'scanning'\n",
        "        \"ground_truth_query\": \"SELECT DISTINCT dst_port FROM df WHERE type = 'scanning';\" # Changed 'portscan' to 'scanning'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Count the number of connections where the 'conn_state' indicates a potential scanning attempt (e.g., 'S0').\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE conn_state = 'S0';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the average 'bytes' transferred in connections labeled as 'normal' vs 'ddos'?\", # Changed 'benign' to 'normal'\n",
        "        \"ground_truth_query\": \"SELECT type, AVG(src_bytes + dst_bytes) FROM df WHERE type IN ('normal', 'ddos') GROUP BY type;\" # Changed 'benign' to 'normal'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Find source IP addresses that initiated more than 1000 connections, and list their count.\",\n",
        "        \"ground_truth_query\": \"SELECT src_ip, COUNT(*) FROM df GROUP BY src_ip HAVING COUNT(*) > 1000;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"List the unique 'service' values present in connections with the 'conn_state' 'RST'.\",\n",
        "        \"ground_truth_query\": \"SELECT DISTINCT service FROM df WHERE conn_state = 'RST';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Count connections where the source IP and destination IP are the same (potential internal scanning/loopback).\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE src_ip = dst_ip;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the most frequent destination ports in the dataset?\",\n",
        "        \"ground_truth_query\": \"SELECT dst_port, COUNT(*) FROM df GROUP BY dst_port ORDER BY COUNT(*) DESC LIMIT 10;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Find connections with a very short duration (e.g., less than 0.001 seconds) and a large number of packets (e.g., > 10), which could indicate unusual activity.\",\n",
        "        \"ground_truth_query\": \"SELECT * FROM df WHERE duration < 0.001 AND (src_pkts + dst_pkts) > 10;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Count the number of unique pairs of source IP and destination IP addresses.\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM (SELECT DISTINCT src_ip, dst_ip FROM df);\"\n",
        "    },\n",
        "     {\n",
        "        \"question\": \"What is the minimum duration for 'normal' connections?\", # Changed 'benign' to 'normal'\n",
        "        \"ground_truth_query\": \"SELECT MIN(duration) FROM df WHERE type = 'normal';\" # Changed 'benign' to 'normal'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"List the unique connection states observed in 'ddos' attacks.\",\n",
        "        \"ground_truth_query\": \"SELECT DISTINCT conn_state FROM df WHERE type = 'ddos';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Count connections with a 'bytes' value of 0 but a duration greater than 0 (potential signaling or control traffic).\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE (src_bytes + dst_bytes) = 0 AND duration > 0;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the top 5 'service' types involved in attacks (where binary label is 1)?\",\n",
        "        # Query uses the 'label' column for binary classification 1 (attack)\n",
        "        \"ground_truth_query\": \"SELECT service, COUNT(*) FROM df WHERE label = 1 GROUP BY service ORDER BY COUNT(*) DESC LIMIT 5;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Find connections originating from source IP '192.168.1.100' that are classified as attacks (where binary label is 1).\",\n",
        "        # Query uses the 'label' column for binary classification 1 (attack)\n",
        "        \"ground_truth_query\": \"SELECT * FROM df WHERE src_ip = '192.168.1.100' AND label = 1;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Count the number of 'FIN' connection states observed for 'TCP' protocol connections.\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE proto = 'TCP' AND conn_state = 'FIN';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the average number of 'packets' for connections with destination port 22 (SSH)?\",\n",
        "        \"ground_truth_query\": \"SELECT AVG(src_pkts + dst_pkts) FROM df WHERE dst_port = 22;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"List source IPs and the number of connections they initiated, where the connections are labeled as 'scanning'.\", # Changed 'portscan' to 'scanning'\n",
        "        \"ground_truth_query\": \"SELECT src_ip, COUNT(*) FROM df WHERE type = 'scanning' GROUP BY src_ip;\" # Changed 'portscan' to 'scanning'\n",
        "    },\n",
        "     {\n",
        "        \"question\": \"Count connections where the duration is 0 and the bytes transferred is also 0 (potential connection attempts with no data).\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE duration = 0 AND (src_bytes + dst_bytes) = 0;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the sum of 'bytes' for connections involving destination port 80 (HTTP)?\",\n",
        "        \"ground_truth_query\": \"SELECT SUM(src_bytes + dst_bytes) FROM df WHERE dst_port = 80;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Find connections with a very high duration (e.g., > 100 seconds) and a 'conn_state' indicating an ongoing or hung connection (e.g., 'EST').\",\n",
        "        \"ground_truth_query\": \"SELECT * FROM df WHERE duration > 100 AND conn_state = 'EST';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Count the number of unique source IP addresses that initiated 'ddos' attacks.\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(DISTINCT src_ip) FROM df WHERE type = 'ddos';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the unique combinations of traffic 'type' and 'proto'?\", # Changed 'attack type' to 'traffic type'\n",
        "        \"ground_truth_query\": \"SELECT DISTINCT type, proto FROM df;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Count connections where the destination port is less than 1024 and the connection type is not 'normal'.\", # Changed 'benign' to 'normal'\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE dst_port < 1024 AND type != 'normal';\" # Changed 'benign' to 'normal'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"List the top 5 source IP addresses involved in 'dos' attacks by connection count.\",\n",
        "        \"ground_truth_query\": \"SELECT src_ip, COUNT(*) FROM df WHERE type = 'dos' GROUP BY src_ip ORDER BY COUNT(*) DESC LIMIT 5;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the average number of 'bytes' transferred in connections with the 'conn_state' 'RST'?\",\n",
        "        \"ground_truth_query\": \"SELECT AVG(src_bytes + dst_bytes) FROM df WHERE conn_state = 'RST';\"\n",
        "    },\n",
        "     {\n",
        "        \"question\": \"Find connections labeled as 'injection' (in the 'type' column) and list their source and destination IPs.\", # Changed 'Web Attack - SQL Injection' to 'injection'\n",
        "        \"ground_truth_query\": \"SELECT src_ip, dst_ip FROM df WHERE type = 'injection';\" # Changed 'Web Attack - SQL Injection' to 'injection'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Count connections where the 'service' is 'dns' and the 'proto' is 'UDP'.\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE service = 'dns' AND proto = 'UDP';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the sum of 'packets' for connections classified as 'scanning'?\", # Changed 'portscan' to 'scanning'\n",
        "        \"ground_truth_query\": \"SELECT SUM(src_pkts + dst_pkts) FROM df WHERE type = 'scanning';\" # Changed 'portscan' to 'scanning'\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"List the unique 'conn_state' values and their counts for connections where the 'type' is 'normal'.\", # Changed 'benign' to 'normal'\n",
        "        \"ground_truth_query\": \"SELECT conn_state, COUNT(*) FROM df WHERE type = 'normal' GROUP BY conn_state;\" # Changed 'benign' to 'normal'\n",
        "    },\n",
        "     {\n",
        "        \"question\": \"Count connections where the source port is the same as the destination port (potential unusual activity or misconfiguration).\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE src_port = dst_port;\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the average duration of connections with a 'SYN' connection state?\",\n",
        "        \"ground_truth_query\": \"SELECT AVG(duration) FROM df WHERE conn_state = 'SYN';\" # Adjust state if 'SYN' is not relevant in your dataset.\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Find connections where the destination IP is a broadcast or multicast address (e.g., 255.255.255.255 or starting with 224.), and list their types.\",\n",
        "        \"ground_truth_query\": \"SELECT type FROM df WHERE dst_ip LIKE '255.255.255.%' OR dst_ip LIKE '224.%';\" # Adjust IP ranges as needed.\n",
        "    },\n",
        "     {\n",
        "        \"question\": \"Count connections where the number of bytes transferred is 0 for 'TCP' protocol connections.\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE (src_bytes + dst_bytes) = 0 AND proto = 'TCP';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the unique connection states observed in 'ddos' attacks?\",\n",
        "        \"ground_truth_query\": \"SELECT DISTINCT conn_state FROM df WHERE type = 'ddos';\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Count connections where the destination port is less than 1000 and the 'conn_state' is 'REJ' (potential firewall block on common services).\",\n",
        "        \"ground_truth_query\": \"SELECT COUNT(*) FROM df WHERE dst_port < 1000 AND conn_state = 'REJ';\" # Adjust port range and state as relevant.\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"List source IPs and the number of connections they initiated, where the connections have a 'bytes' value of 0 and the type is not 'normal'.\", # Changed 'benign' to 'normal'\n",
        "        \"ground_truth_query\": \"SELECT src_ip, COUNT(*) FROM df WHERE (src_bytes + dst_bytes) = 0 AND type != 'normal' GROUP BY src_ip;\" # Changed 'benign' to 'normal'\n",
        "    },\n",
        "]\n",
        "\n",
        "# Select at least 30 questions. If the list has more than 30, select a random subset.\n",
        "sql_eval_subset_with_queries = sql_eval_data_with_queries\n",
        "if len(sql_eval_data_with_queries) < 30:\n",
        "    print(f\"Warning: Only {len(sql_eval_data_with_queries)} questions available. Please add more cybersecurity-relevant question-ground truth pairs to 'sql_eval_data_with_queries' to reach at least 30.\")\n",
        "    # If you absolutely need 30 for the evaluation to run, you could potentially\n",
        "    # duplicate some entries, but this will skew the evaluation results.\n",
        "    # while len(sql_eval_subset_with_queries) < 30:\n",
        "    #     sql_eval_subset_with_queries.append(random.choice(sql_eval_data_with_queries))\n",
        "elif len(sql_eval_data_with_queries) > 30:\n",
        "     sql_eval_subset_with_queries = random.sample(sql_eval_data_with_queries, 30) # Select exactly 30 random questions\n",
        "\n",
        "\n",
        "sql_results = []\n",
        "# Ensure 'df' exists and get its columns if it was successfully loaded in Cell 4\n",
        "schema = df.columns.tolist() if 'df' in globals() and not df.empty else []\n",
        "\n",
        "if not schema:\n",
        "    print(\"Error: DataFrame 'df' not found or is empty. Please ensure Cell 4 ran successfully and the dataset was loaded correctly.\")\n",
        "else:\n",
        "    print(f\"Simulating SQL queries for {len(sql_eval_subset_with_queries)} cybersecurity-relevant questions based on the loaded dataset...\")\n",
        "\n",
        "    for item in sql_eval_subset_with_queries:\n",
        "        question = item[\"question\"]\n",
        "        ground_truth_query = item[\"ground_truth_query\"]\n",
        "\n",
        "        # Execute the ground truth query to get the actual result\n",
        "        try:\n",
        "            ground_truth_df = pysqldf(ground_truth_query)\n",
        "            ground_truth_string = ground_truth_df.to_string(index=False)\n",
        "        except Exception as e:\n",
        "            print(f\"Error executing GROUND TRUTH SQL query for question '{question}': {e}\")\n",
        "            ground_truth_string = f\"ERROR executing ground truth query: {e}\"\n",
        "            # You might want to skip this question if ground truth cannot be generated\n",
        "            # continue\n",
        "\n",
        "\n",
        "        # Simulate the model's text-to-sql process to get the model's answer and query\n",
        "        model_answer, generated_sql, _ = text_to_sql_and_execute(question, schema)\n",
        "\n",
        "        sql_results.append({\n",
        "            \"question\": question,\n",
        "            \"answer\": model_answer,\n",
        "            \"ground_truth\": ground_truth_string, # Use the dynamically generated ground truth\n",
        "            \"contexts\": [f\"Generated SQL: {generated_sql}\"] # Using generated SQL as context for Ragas evaluation\n",
        "        })\n",
        "\n",
        "    sql_eval_dataset = Dataset.from_list(sql_results)\n",
        "    print(\"--- SQL Evaluation Dataset (with generated answers and dynamic ground truths) ---\")\n",
        "    print(f\"Dataset size: {len(sql_eval_dataset)}\")\n",
        "    if len(sql_eval_dataset) > 0:\n",
        "        print(\"First item:\")\n",
        "        print(sql_eval_dataset[0])\n",
        "    else:\n",
        "        print(\"No evaluation data generated. Check for errors during simulation.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulating SQL queries for 30 cybersecurity-relevant questions based on the loaded dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SQL Evaluation Dataset (with generated answers and dynamic ground truths) ---\n",
            "Dataset size: 30\n",
            "First item:\n",
            "{'question': \"Count connections where the 'service' is 'dns' and the 'proto' is 'UDP'.\", 'answer': 'Error: LLM generated invalid or empty SQL.', 'ground_truth': ' COUNT(*)\\n        0', 'contexts': [\"Generated SQL: ```sql\\nSELECT COUNT(*)\\nFROM df\\nWHERE service = 'dns' AND proto = 'UDP';\\n```\"]}\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "ktEEd8Pwiict",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d77677-8653-4579-8643-fbe1cd281032"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 10 question-ground truth pairs from the SQL evaluation dataset in a table\n",
        "if 'sql_eval_dataset' in globals():\n",
        "    print(\"--- First 10 SQL Evaluation Pairs (Table Format) ---\")\n",
        "    data_to_display = []\n",
        "    for i in range(min(10, len(sql_eval_dataset))):\n",
        "        data_to_display.append({\n",
        "            \"Pair #\": i + 1,\n",
        "            \"Question\": sql_eval_dataset[i]['question'],\n",
        "            \"Ground Truth\": sql_eval_dataset[i]['ground_truth']\n",
        "        })\n",
        "\n",
        "    # Create a pandas DataFrame for easy tabular printing\n",
        "    display_df = pd.DataFrame(data_to_display)\n",
        "    display(display_df) # Use display() for better table rendering in Colab\n",
        "else:\n",
        "    print(\"SQL evaluation dataset 'sql_eval_dataset' not found. Please run Cell 6 first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "lfEDFb0yPuKB",
        "outputId": "567b7daf-d023-4ec0-fa36-7bd917bffbd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- First 10 SQL Evaluation Pairs (Table Format) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Pair #                                           Question  \\\n",
              "0       1  Count connections where the 'service' is 'dns'...   \n",
              "1       2  Count connections where the destination port i...   \n",
              "2       3  Count connections where the source port is the...   \n",
              "3       4  What are the most frequent destination ports i...   \n",
              "4       5  Find connections with a very short duration (e...   \n",
              "5       6  Count connections where the duration is 0 and ...   \n",
              "6       7  Find connections with a very high duration (e....   \n",
              "7       8  What are the top 5 'service' types involved in...   \n",
              "8       9  What is the average duration of connections wi...   \n",
              "9      10  Count connections with a 'bytes' value of 0 bu...   \n",
              "\n",
              "                                        Ground Truth  \n",
              "0                                COUNT(*)\\n        0  \n",
              "1                                COUNT(*)\\n      752  \n",
              "2                                COUNT(*)\\n      107  \n",
              "3   dst_port  COUNT(*)\\n       80       370\\n    ...  \n",
              "4  Empty DataFrame\\nColumns: [src_ip, src_port, d...  \n",
              "5                                COUNT(*)\\n      253  \n",
              "6  Empty DataFrame\\nColumns: [src_ip, src_port, d...  \n",
              "7  service  COUNT(*)\\n      -       564\\n   http ...  \n",
              "8                       AVG(duration)\\n         None  \n",
              "9                                COUNT(*)\\n      333  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42a873ac-a4ca-4b53-82d8-f5232674e37b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pair #</th>\n",
              "      <th>Question</th>\n",
              "      <th>Ground Truth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Count connections where the 'service' is 'dns'...</td>\n",
              "      <td>COUNT(*)\\n        0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Count connections where the destination port i...</td>\n",
              "      <td>COUNT(*)\\n      752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Count connections where the source port is the...</td>\n",
              "      <td>COUNT(*)\\n      107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>What are the most frequent destination ports i...</td>\n",
              "      <td>dst_port  COUNT(*)\\n       80       370\\n    ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Find connections with a very short duration (e...</td>\n",
              "      <td>Empty DataFrame\\nColumns: [src_ip, src_port, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Count connections where the duration is 0 and ...</td>\n",
              "      <td>COUNT(*)\\n      253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Find connections with a very high duration (e....</td>\n",
              "      <td>Empty DataFrame\\nColumns: [src_ip, src_port, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>What are the top 5 'service' types involved in...</td>\n",
              "      <td>service  COUNT(*)\\n      -       564\\n   http ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>What is the average duration of connections wi...</td>\n",
              "      <td>AVG(duration)\\n         None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Count connections with a 'bytes' value of 0 bu...</td>\n",
              "      <td>COUNT(*)\\n      333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42a873ac-a4ca-4b53-82d8-f5232674e37b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-42a873ac-a4ca-4b53-82d8-f5232674e37b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-42a873ac-a4ca-4b53-82d8-f5232674e37b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-172384cb-1b60-4912-b2c7-d5a449d087cc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-172384cb-1b60-4912-b2c7-d5a449d087cc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-172384cb-1b60-4912-b2c7-d5a449d087cc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_38e381e8-0ab5-4014-ba2f-eb531e335fa8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('display_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_38e381e8-0ab5-4014-ba2f-eb531e335fa8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('display_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "display_df",
              "summary": "{\n  \"name\": \"display_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Pair #\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"What is the average duration of connections with a 'SYN' connection state?\",\n          \"Count connections where the destination port is less than 1024 and the connection type is not 'normal'.\",\n          \"Count connections where the duration is 0 and the bytes transferred is also 0 (potential connection attempts with no data).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ground Truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"AVG(duration)\\n         None\",\n          \" COUNT(*)\\n      752\",\n          \" COUNT(*)\\n      253\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Using dataframe display_df: length scatter\n",
        "\n",
        "import altair as alt\n",
        "# Calculate the length of the 'Question' and 'Ground Truth' columns\n",
        "display_df['Question_Length'] = display_df['Question'].str.len()\n",
        "display_df['Ground_Truth_Length'] = display_df['Ground Truth'].str.len()\n",
        "# Create a scatter plot with 'Question_Length' on the x-axis and 'Ground_Truth_Length' on the y-axis\n",
        "chart = alt.Chart(display_df).mark_point().encode(\n",
        "    x='Question_Length',\n",
        "    y='Ground_Truth_Length'\n",
        ")\n",
        "chart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "GZbXUOVmOYVZ",
        "outputId": "554690ac-2984-4d63-e42b-ff4d6a3dabde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-6d37d0c1949940b2a8c390d664cd1889.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-6d37d0c1949940b2a8c390d664cd1889.vega-embed details,\n",
              "  #altair-viz-6d37d0c1949940b2a8c390d664cd1889.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-6d37d0c1949940b2a8c390d664cd1889\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-6d37d0c1949940b2a8c390d664cd1889\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-6d37d0c1949940b2a8c390d664cd1889\");\n",
              "    }\n",
              "\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      let deps = [\"vega-embed\"];\n",
              "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-c44852b0a28dd6a0c5428f6dd2071040\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"x\": {\"field\": \"Question_Length\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Ground_Truth_Length\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-c44852b0a28dd6a0c5428f6dd2071040\": [{\"Pair #\": 1, \"Question\": \"Count connections where the 'service' is 'dns' and the 'proto' is 'UDP'.\", \"Ground Truth\": \" COUNT(*)\\n        0\", \"Question_Length\": 72, \"Ground_Truth_Length\": 19}, {\"Pair #\": 2, \"Question\": \"Count connections where the destination port is less than 1024 and the connection type is not 'normal'.\", \"Ground Truth\": \" COUNT(*)\\n      752\", \"Question_Length\": 103, \"Ground_Truth_Length\": 19}, {\"Pair #\": 3, \"Question\": \"Count connections where the source port is the same as the destination port (potential unusual activity or misconfiguration).\", \"Ground Truth\": \" COUNT(*)\\n      107\", \"Question_Length\": 125, \"Ground_Truth_Length\": 19}, {\"Pair #\": 4, \"Question\": \"What are the most frequent destination ports in the dataset?\", \"Ground Truth\": \" dst_port  COUNT(*)\\n       80       370\\n       53       163\\n      445        69\\n      443        61\\n     8080        45\\n       21        21\\n     4444        10\\n    10502         6\\n      135         6\\n    51782         5\", \"Question_Length\": 60, \"Ground_Truth_Length\": 219}, {\"Pair #\": 5, \"Question\": \"Find connections with a very short duration (e.g., less than 0.001 seconds) and a large number of packets (e.g., > 10), which could indicate unusual activity.\", \"Ground Truth\": \"Empty DataFrame\\nColumns: [src_ip, src_port, dst_ip, dst_port, proto, service, duration, src_bytes, dst_bytes, conn_state, missed_bytes, src_pkts, src_ip_bytes, dst_pkts, dst_ip_bytes, dns_query, dns_rejected, ssl_version, ssl_cipher, http_method, http_uri, http_version, label, type]\\nIndex: []\", \"Question_Length\": 158, \"Ground_Truth_Length\": 293}, {\"Pair #\": 6, \"Question\": \"Count connections where the duration is 0 and the bytes transferred is also 0 (potential connection attempts with no data).\", \"Ground Truth\": \" COUNT(*)\\n      253\", \"Question_Length\": 123, \"Ground_Truth_Length\": 19}, {\"Pair #\": 7, \"Question\": \"Find connections with a very high duration (e.g., > 100 seconds) and a 'conn_state' indicating an ongoing or hung connection (e.g., 'EST').\", \"Ground Truth\": \"Empty DataFrame\\nColumns: [src_ip, src_port, dst_ip, dst_port, proto, service, duration, src_bytes, dst_bytes, conn_state, missed_bytes, src_pkts, src_ip_bytes, dst_pkts, dst_ip_bytes, dns_query, dns_rejected, ssl_version, ssl_cipher, http_method, http_uri, http_version, label, type]\\nIndex: []\", \"Question_Length\": 139, \"Ground_Truth_Length\": 293}, {\"Pair #\": 8, \"Question\": \"What are the top 5 'service' types involved in attacks (where binary label is 1)?\", \"Ground Truth\": \"service  COUNT(*)\\n      -       564\\n   http       187\\n    dns       114\\n    ssl        26\\n    ftp         4\", \"Question_Length\": 81, \"Ground_Truth_Length\": 107}, {\"Pair #\": 9, \"Question\": \"What is the average duration of connections with a 'SYN' connection state?\", \"Ground Truth\": \"AVG(duration)\\n         None\", \"Question_Length\": 74, \"Ground_Truth_Length\": 27}, {\"Pair #\": 10, \"Question\": \"Count connections with a 'bytes' value of 0 but a duration greater than 0 (potential signaling or control traffic).\", \"Ground Truth\": \" COUNT(*)\\n      333\", \"Question_Length\": 115, \"Ground_Truth_Length\": 19}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Using dataframe display_df: scatter plot\n",
        "\n",
        "import altair as alt\n",
        "\n",
        "# Create a scatter plot of 'Pair #' vs 'Ground Truth'\n",
        "chart = alt.Chart(display_df).mark_point().encode(\n",
        "    x='Pair #',\n",
        "    y='Ground Truth'\n",
        ")\n",
        "\n",
        "# Display the chart\n",
        "chart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "N7w3mBKlOJtf",
        "outputId": "5cbd6ceb-c7c8-4b00-877b-26155354fea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-e5ea82df23944eff8eed68dfa448d12e.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-e5ea82df23944eff8eed68dfa448d12e.vega-embed details,\n",
              "  #altair-viz-e5ea82df23944eff8eed68dfa448d12e.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-e5ea82df23944eff8eed68dfa448d12e\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-e5ea82df23944eff8eed68dfa448d12e\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-e5ea82df23944eff8eed68dfa448d12e\");\n",
              "    }\n",
              "\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      let deps = [\"vega-embed\"];\n",
              "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-c44852b0a28dd6a0c5428f6dd2071040\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"x\": {\"field\": \"Pair #\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Ground Truth\", \"type\": \"nominal\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-c44852b0a28dd6a0c5428f6dd2071040\": [{\"Pair #\": 1, \"Question\": \"Count connections where the 'service' is 'dns' and the 'proto' is 'UDP'.\", \"Ground Truth\": \" COUNT(*)\\n        0\", \"Question_Length\": 72, \"Ground_Truth_Length\": 19}, {\"Pair #\": 2, \"Question\": \"Count connections where the destination port is less than 1024 and the connection type is not 'normal'.\", \"Ground Truth\": \" COUNT(*)\\n      752\", \"Question_Length\": 103, \"Ground_Truth_Length\": 19}, {\"Pair #\": 3, \"Question\": \"Count connections where the source port is the same as the destination port (potential unusual activity or misconfiguration).\", \"Ground Truth\": \" COUNT(*)\\n      107\", \"Question_Length\": 125, \"Ground_Truth_Length\": 19}, {\"Pair #\": 4, \"Question\": \"What are the most frequent destination ports in the dataset?\", \"Ground Truth\": \" dst_port  COUNT(*)\\n       80       370\\n       53       163\\n      445        69\\n      443        61\\n     8080        45\\n       21        21\\n     4444        10\\n    10502         6\\n      135         6\\n    51782         5\", \"Question_Length\": 60, \"Ground_Truth_Length\": 219}, {\"Pair #\": 5, \"Question\": \"Find connections with a very short duration (e.g., less than 0.001 seconds) and a large number of packets (e.g., > 10), which could indicate unusual activity.\", \"Ground Truth\": \"Empty DataFrame\\nColumns: [src_ip, src_port, dst_ip, dst_port, proto, service, duration, src_bytes, dst_bytes, conn_state, missed_bytes, src_pkts, src_ip_bytes, dst_pkts, dst_ip_bytes, dns_query, dns_rejected, ssl_version, ssl_cipher, http_method, http_uri, http_version, label, type]\\nIndex: []\", \"Question_Length\": 158, \"Ground_Truth_Length\": 293}, {\"Pair #\": 6, \"Question\": \"Count connections where the duration is 0 and the bytes transferred is also 0 (potential connection attempts with no data).\", \"Ground Truth\": \" COUNT(*)\\n      253\", \"Question_Length\": 123, \"Ground_Truth_Length\": 19}, {\"Pair #\": 7, \"Question\": \"Find connections with a very high duration (e.g., > 100 seconds) and a 'conn_state' indicating an ongoing or hung connection (e.g., 'EST').\", \"Ground Truth\": \"Empty DataFrame\\nColumns: [src_ip, src_port, dst_ip, dst_port, proto, service, duration, src_bytes, dst_bytes, conn_state, missed_bytes, src_pkts, src_ip_bytes, dst_pkts, dst_ip_bytes, dns_query, dns_rejected, ssl_version, ssl_cipher, http_method, http_uri, http_version, label, type]\\nIndex: []\", \"Question_Length\": 139, \"Ground_Truth_Length\": 293}, {\"Pair #\": 8, \"Question\": \"What are the top 5 'service' types involved in attacks (where binary label is 1)?\", \"Ground Truth\": \"service  COUNT(*)\\n      -       564\\n   http       187\\n    dns       114\\n    ssl        26\\n    ftp         4\", \"Question_Length\": 81, \"Ground_Truth_Length\": 107}, {\"Pair #\": 9, \"Question\": \"What is the average duration of connections with a 'SYN' connection state?\", \"Ground Truth\": \"AVG(duration)\\n         None\", \"Question_Length\": 74, \"Ground_Truth_Length\": 27}, {\"Pair #\": 10, \"Question\": \"Count connections with a 'bytes' value of 0 but a duration greater than 0 (potential signaling or control traffic).\", \"Ground Truth\": \" COUNT(*)\\n      333\", \"Question_Length\": 115, \"Ground_Truth_Length\": 19}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual: This scatter plot visualizes the relationship between the lengths of questions and their corresponding ground truths, with the x-axis representing question length and the y-axis representing ground truth length. The data points are mostly clustered in the middle range, indicating that moderate-length questions tend to have moderate-length ground truths. However, there is noticeable variability, with some shorter questions paired with longer ground truths and vice versa. This suggests that while there is a general trend of moderate-length pairings, the lengths of questions and ground truths do not always correspond directly, highlighting variability in the dataset.\n",
        "\n",
        "Visual1: This scatter plot examines the relationship between the lengths of questions and their corresponding ground truths, with the x-axis representing question length and the y-axis representing ground truth length. The data reveals a notable outlier where a very long ground truth (approximately 4.5 million characters) corresponds to a relatively short question (around 80 characters), suggesting a significant imbalance in length for this particular pair. The remaining data points cluster at the lower end of the plot, indicating that most questions and ground truths are relatively short, with lengths generally under 140 characters. This visualization highlights that while most pairs are concise, there are exceptions where ground truths are disproportionately lengthy compared to their corresponding questions.\n",
        "\n",
        "scatter plot: This scatter plot visualizes question-answer pairs designed to evaluate a Retrieval-Augmented Generation (RAG) system, where the dataset is derived from network traffic analysis (pcap files) containing real-world cyber attack data. The x-axis represents different pair numbers (0-10), while the y-axis shows ground truth values that are uniformly 0 across all pairs. This suggests that for this specific subset of data (with a low severity level and associated with a particular country code), all the ground truth values are consistently 0. The chart indicates these pairs will be used to test the RAG system's ability to handle cybersecurity-related questions, though the uniform ground truth values of 0 may reflect a particular pattern or baseline condition in this dataset subset, possibly representing non-malicious or neutral cases in the cyber attack context."
      ],
      "metadata": {
        "id": "xxR4TDqMSjOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 4: Prepare Evaluation Setup**\n",
        "Before running the Ragas evaluation, Ragas needs its own LLM to perform the necessary comparisons and checks between the generated answers, ground truth, and contexts. So we set our LLM OpenRouter API key and base URL as environment variables."
      ],
      "metadata": {
        "id": "yFsIufXjVpDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 1 (Base LLM: Mistral): Prepare Evaluation Setup**\n",
        "Imports & API Setup for Mistral/OpenRouter."
      ],
      "metadata": {
        "id": "jKlVr_Y-avxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load secrets configured in Colab's sidebar\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Assuming your OpenRouter API key secret is named 'OPENROUTER_API_KEY' in the Colab Secrets sidebar\n",
        "# Replace 'OPENROUTER_API_KEY' if you used a different name for your secret\n",
        "try:\n",
        "    openrouter_api_key = userdata.get('OpenrouterAPI_rageval_obrina')\n",
        "    # Set the environment variable that langchain/ragas expects\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openrouter_api_key\n",
        "    print(\"OpenRouter API key loaded from Colab Secrets and set as OPENAI_API_KEY environment variable.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Error: 'OPENROUTER_API_KEY' not found in Colab Secrets.\")\n",
        "    print(\"Please add your OpenRouter API key to the Colab Secrets sidebar with the name 'OPENROUTER_API_KEY'.\")\n",
        "    # You might want to stop execution here if the key is not found\n",
        "    # raise ValueError(\"'OPENROUTER_API_KEY' secret not found.\")\n",
        "\n",
        "# Set the base URL for OpenRouter (it's an OpenAI-compatible endpoint)\n",
        "# This can be hardcoded as it's not a sensitive secret\n",
        "os.environ[\"OPENAI_BASE_URL\"] = \"https://openrouter.ai/api/v1\"\n",
        "print(\"OpenRouter API base URL environment variable set.\")\n",
        "\n",
        "# You can optionally verify the environment variables are set (without printing the key value)\n",
        "# print(f\"OPENAI_API_KEY is set: {'OPENAI_API_KEY' in os.environ}\")\n",
        "# print(f\"OPENAI_API_BASE is set: {'OPENAI_API_BASE' in os.environ}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBr58pzQbfxw",
        "outputId": "05dc6a3e-ca31-44c0-dd05-6c21a1081c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenRouter API key loaded from Colab Secrets and set as OPENAI_API_KEY environment variable.\n",
            "OpenRouter API base URL environment variable set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 2 (Base LLM: Mistral): Re-load data and define pysqldf**\n",
        "Re-load ToN-IoT Dataset."
      ],
      "metadata": {
        "id": "vIRjGLZzdCoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-load the dataframe 'df' and define 'pysqldf' if they are not already in the global scope\n",
        "# (Copying content from Cell 5 for robustness)\n",
        "LABELED_CSV_FILE = '/content/drive/MyDrive/PHDS/experiment/bizbot-segolily/toniot-dataset/sampled_toniot_dataset.csv'\n",
        "\n",
        "print(f\"Attempting to load dataset from Google Drive: {LABELED_CSV_FILE}\")\n",
        "\n",
        "if not os.path.exists(LABELED_CSV_FILE):\n",
        "    print(f\"Error: File not found at '{LABELED_CSV_FILE}'\")\n",
        "    print(\"Please double-check the path in Google Drive.\")\n",
        "    print(\"Make sure Google Drive is mounted and the path copied from the Colab file explorer is correct.\")\n",
        "else:\n",
        "    print(\"File found. Loading into pandas DataFrame...\")\n",
        "    try:\n",
        "        try:\n",
        "            df = pd.read_csv(LABELED_CSV_FILE)\n",
        "        except UnicodeDecodeError:\n",
        "            print(\"UTF-8 decode failed, trying latin1 encoding...\")\n",
        "            df = pd.read_csv(LABELED_CSV_FILE, encoding='latin1')\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred while reading the CSV: {e}\")\n",
        "            raise e\n",
        "\n",
        "    except FileNotFoundError:\n",
        "         print(f\"Error: File not found at '{LABELED_CSV_FILE}'. Please ensure the path is correct.\")\n",
        "         raise\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the CSV file: {e}\")\n",
        "        print(\"Please check the file format and content.\")\n",
        "        raise\n",
        "\n",
        "    df.columns = df.columns.str.strip().str.replace('[^a-zA-Z0-9_]', '_', regex=True)\n",
        "    pysqldf = lambda q: sqldf(q, globals())\n",
        "\n",
        "    print(\"Data loaded. Columns are now SQL-friendly.\")\n",
        "    print(\"\\n--- DataFrame Head ---\")\n",
        "    display(df.head())\n",
        "    print(\"\\n--- DataFrame Info ---\")\n",
        "    df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "CncOVkAfdC6C",
        "outputId": "ffea702a-562a-424e-885e-55522feca145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load dataset from Google Drive: /content/drive/MyDrive/PHDS/experiment/bizbot-segolily/toniot-dataset/sampled_toniot_dataset.csv\n",
            "File found. Loading into pandas DataFrame...\n",
            "Data loaded. Columns are now SQL-friendly.\n",
            "\n",
            "--- DataFrame Head ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          src_ip  src_port        dst_ip  dst_port proto service  duration  \\\n",
              "0  192.168.1.193     49739  192.168.1.33        80   tcp       -  0.000018   \n",
              "1  192.168.1.193     49401  192.168.1.37      8080   tcp       -  0.000138   \n",
              "2  192.168.1.193     49663  192.168.1.33        80   tcp       -  0.000022   \n",
              "3  192.168.1.193     49345  192.168.1.37      8080   tcp       -  0.000009   \n",
              "4  192.168.1.193     49875  192.168.1.37      8080   tcp       -  0.000142   \n",
              "\n",
              "   src_bytes  dst_bytes conn_state  ...  dst_ip_bytes  dns_query  \\\n",
              "0          0          0        REJ  ...            40          -   \n",
              "1          0          0        REJ  ...            40          -   \n",
              "2          0          0        REJ  ...            40          -   \n",
              "3          0          0        REJ  ...            40          -   \n",
              "4          0          0        REJ  ...            40          -   \n",
              "\n",
              "   dns_rejected  ssl_version  ssl_cipher http_method http_uri http_version  \\\n",
              "0             -            -           -           -        -            -   \n",
              "1             -            -           -           -        -            -   \n",
              "2             -            -           -           -        -            -   \n",
              "3             -            -           -           -        -            -   \n",
              "4             -            -           -           -        -            -   \n",
              "\n",
              "  label      type  \n",
              "0     1  backdoor  \n",
              "1     1  backdoor  \n",
              "2     1  backdoor  \n",
              "3     1  backdoor  \n",
              "4     1  backdoor  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fadf182-4cd0-41a6-93ed-9b47644ef632\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src_ip</th>\n",
              "      <th>src_port</th>\n",
              "      <th>dst_ip</th>\n",
              "      <th>dst_port</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>conn_state</th>\n",
              "      <th>...</th>\n",
              "      <th>dst_ip_bytes</th>\n",
              "      <th>dns_query</th>\n",
              "      <th>dns_rejected</th>\n",
              "      <th>ssl_version</th>\n",
              "      <th>ssl_cipher</th>\n",
              "      <th>http_method</th>\n",
              "      <th>http_uri</th>\n",
              "      <th>http_version</th>\n",
              "      <th>label</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>192.168.1.193</td>\n",
              "      <td>49739</td>\n",
              "      <td>192.168.1.33</td>\n",
              "      <td>80</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>REJ</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "      <td>backdoor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>192.168.1.193</td>\n",
              "      <td>49401</td>\n",
              "      <td>192.168.1.37</td>\n",
              "      <td>8080</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>REJ</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "      <td>backdoor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>192.168.1.193</td>\n",
              "      <td>49663</td>\n",
              "      <td>192.168.1.33</td>\n",
              "      <td>80</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>REJ</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "      <td>backdoor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>192.168.1.193</td>\n",
              "      <td>49345</td>\n",
              "      <td>192.168.1.37</td>\n",
              "      <td>8080</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>REJ</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "      <td>backdoor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>192.168.1.193</td>\n",
              "      <td>49875</td>\n",
              "      <td>192.168.1.37</td>\n",
              "      <td>8080</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>REJ</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>1</td>\n",
              "      <td>backdoor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fadf182-4cd0-41a6-93ed-9b47644ef632')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3fadf182-4cd0-41a6-93ed-9b47644ef632 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3fadf182-4cd0-41a6-93ed-9b47644ef632');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9fd896bc-3e61-48e1-80d1-dc562de5ee22\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9fd896bc-3e61-48e1-80d1-dc562de5ee22')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9fd896bc-3e61-48e1-80d1-dc562de5ee22 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- DataFrame Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 24 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   src_ip        1000 non-null   object \n",
            " 1   src_port      1000 non-null   int64  \n",
            " 2   dst_ip        1000 non-null   object \n",
            " 3   dst_port      1000 non-null   int64  \n",
            " 4   proto         1000 non-null   object \n",
            " 5   service       1000 non-null   object \n",
            " 6   duration      1000 non-null   float64\n",
            " 7   src_bytes     1000 non-null   int64  \n",
            " 8   dst_bytes     1000 non-null   int64  \n",
            " 9   conn_state    1000 non-null   object \n",
            " 10  missed_bytes  1000 non-null   int64  \n",
            " 11  src_pkts      1000 non-null   int64  \n",
            " 12  src_ip_bytes  1000 non-null   int64  \n",
            " 13  dst_pkts      1000 non-null   int64  \n",
            " 14  dst_ip_bytes  1000 non-null   int64  \n",
            " 15  dns_query     1000 non-null   object \n",
            " 16  dns_rejected  1000 non-null   object \n",
            " 17  ssl_version   1000 non-null   object \n",
            " 18  ssl_cipher    1000 non-null   object \n",
            " 19  http_method   1000 non-null   object \n",
            " 20  http_uri      1000 non-null   object \n",
            " 21  http_version  1000 non-null   object \n",
            " 22  label         1000 non-null   int64  \n",
            " 23  type          1000 non-null   object \n",
            "dtypes: float64(1), int64(10), object(13)\n",
            "memory usage: 187.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 3 (Base LLM: Mistral): Define the Mistral-based text-to-SQL function**\n",
        "Define the function that utilize mistral LLM as an analyst to answer the SQL data query questions."
      ],
      "metadata": {
        "id": "gPxi8nAydZkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure df and pysqldf are available\n",
        "if 'df' in globals() and 'pysqldf' in globals():\n",
        "\n",
        "    # Initialize the OpenAI client (which uses the OpenRouter API key and base URL)\n",
        "    # Import the OpenAI class\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI()\n",
        "\n",
        "    def text_to_sql_mistral(natural_language_question, dataframe_schema):\n",
        "        \"\"\"\n",
        "        Uses the Mistral 7B Instruct model via OpenRouter to convert a natural language question\n",
        "        into a SQL query, then executes the query against the dataframe.\n",
        "        \"\"\"\n",
        "        # Specify the Mistral model name provided by OpenRouter\n",
        "        # Check OpenRouter documentation for the exact model ID, 'mistralai/mistral-7b-instruct' is common\n",
        "        mistral_model_name = \"mistralai/mistral-7b-instruct\"\n",
        "\n",
        "        # Craft a prompt for Mistral to generate SQL\n",
        "        # IMPROVED PROMPT: Added emphasis on using column names directly (no single quotes)\n",
        "        # and providing examples for counting distinct pairs.\n",
        "        prompt_for_sql_generation = f\"\"\"\n",
        "You are a helpful assistant that translates natural language questions into SQL queries for a pandas DataFrame named 'df'.\n",
        "The DataFrame 'df' has the following columns: {dataframe_schema}.\n",
        "When referring to column names like 'src_ip', 'dst_ip', 'duration', etc., use the column name directly without any quotes.\n",
        "Generate a concise SQL query that answers the following question based on the 'df' DataFrame.\n",
        "For example, to count distinct source IPs, use \"SELECT COUNT(DISTINCT src_ip) FROM df;\".\n",
        "To count distinct pairs of source and destination IPs, use \"SELECT COUNT(*) FROM (SELECT DISTINCT src_ip, dst_ip FROM df);\".\n",
        "Only return the SQL query and nothing else.\n",
        "\n",
        "Question: {natural_language_question}\n",
        "\n",
        "SQL Query:\n",
        "\"\"\"\n",
        "        generated_sql = \"SELECT 'Error: LLM failed to generate SQL';\"  # Default error\n",
        "        completion_content = None # Initialize to None\n",
        "\n",
        "        try:\n",
        "            # Use the OpenAI client to get a completion from the Mistral model\n",
        "            completion = client.chat.completions.create(\n",
        "                model=mistral_model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates natural language to SQL.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt_for_sql_generation}\n",
        "                ],\n",
        "                max_tokens=100,  # Adjust based on expected query length\n",
        "                temperature=0.01,  # Set low for deterministic output\n",
        "                # Add other parameters as needed by the API\n",
        "            )\n",
        "\n",
        "            # Extract the generated SQL query from the response\n",
        "            # The exact way to extract depends on the API response structure\n",
        "            # Assuming the response provides the generated text in completion.choices[0].message.content\n",
        "            if completion.choices and completion.choices[0].message.content:\n",
        "                completion_content = completion.choices[0].message.content.strip()\n",
        "                generated_sql = completion_content\n",
        "                # Basic cleaning: remove any leading/trailing text the LLM might add\n",
        "                if generated_sql.lower().startswith(\"sql query:\"):\n",
        "                    generated_sql = generated_sql[len(\"sql query:\"):].strip()\n",
        "                # Remove common markdown code block formatting if present\n",
        "                if generated_sql.startswith(\"```sql\"):\n",
        "                    generated_sql = generated_sql[6:].strip()\n",
        "                if generated_sql.endswith(\"```\"):\n",
        "                    generated_sql = generated_sql[:-3].strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            generated_sql = f\"SELECT 'Error generating SQL: {e}';\"  # Provide the exception message\n",
        "\n",
        "        print(f\"Generated SQL: {generated_sql}\")  # For debugging\n",
        "\n",
        "        try:\n",
        "            # Execute the generated SQL query using pysqldf\n",
        "            # Ensure df is accessible in the environment where pysqldf runs\n",
        "            # Convert the result DataFrame to a string for consistency with the other function\n",
        "            result_df = pysqldf(generated_sql)\n",
        "            model_answer_string = result_df.to_string(index=False)\n",
        "            # Return the answer string, the generated SQL, and the raw LLM response (or None if not easily available)\n",
        "            return model_answer_string, generated_sql, completion_content\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error executing SQL: {e}\")\n",
        "            # Return error strings for the answer and SQL, and None for the raw response\n",
        "            return f\"Error executing SQL: {e}\", generated_sql, completion_content\n",
        "        except Exception as e:\n",
        "            generated_sql = f\"SELECT 'Error generating SQL: {e}';\"  # Provide the exception message\n",
        "\n",
        "        print(f\"Generated SQL: {generated_sql}\")  # For debugging\n",
        "\n",
        "        try:\n",
        "            # Execute the generated SQL query using pysqldf\n",
        "            # Ensure df is accessible in the environment where pysqldf runs\n",
        "            # Convert the result DataFrame to a string for consistency with the other function\n",
        "            result_df = pysqldf(generated_sql)\n",
        "            model_answer_string = result_df.to_string(index=False)\n",
        "            # Return the answer string, the generated SQL, and the raw LLM response (or None if not easily available)\n",
        "            return model_answer_string, generated_sql, completion.choices[0].message.content if completion.choices else None\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error executing SQL: {e}\")\n",
        "            # Return error strings for the answer and SQL, and None for the raw response\n",
        "            return f\"Error executing SQL: {e}\", generated_sql, None"
      ],
      "metadata": {
        "id": "PnMDGk0qd9a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 4 (Base LLM: Mistral): Prepare Mistral Evaluation Dataset**\n",
        "Refactoring the Mistral LLM evaluation dataset."
      ],
      "metadata": {
        "id": "QgL0OhO9dhkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure df, pysqldf, and text_to_sql_mistral are available\n",
        "if 'df' in globals() and 'pysqldf' in globals() and 'text_to_sql_mistral' in globals():\n",
        "\n",
        "    # Re-use the same questions and ground truths as the Segolily evaluation\n",
        "    # This is crucial for a fair comparison\n",
        "    # (Assuming sql_eval_subset_with_queries is available from Cell 6 of the original notebook)\n",
        "    if 'sql_eval_subset_with_queries' not in globals():\n",
        "         print(\"Error: 'sql_eval_subset_with_queries' not found. Please run Cell 6 of the original notebook first.\")\n",
        "    else:\n",
        "        print(f\"Simulating Mistral SQL queries for the same {len(sql_eval_subset_with_queries)} questions...\")\n",
        "\n",
        "        mistral_results = []\n",
        "        schema = df.columns.tolist() if 'df' in globals() and not df.empty else []\n",
        "\n",
        "        if not schema:\n",
        "            print(\"Error: DataFrame 'df' not found or is empty.\")\n",
        "        else:\n",
        "            for item in sql_eval_subset_with_queries:\n",
        "                question = item[\"question\"]\n",
        "                ground_truth_query = item[\"ground_truth_query\"]\n",
        "\n",
        "                # Get the ground truth (same as before)\n",
        "                try:\n",
        "                    ground_truth_df = pysqldf(ground_truth_query)\n",
        "                    ground_truth_string = ground_truth_df.to_string(index=False)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error executing GROUND TRUTH SQL query for question '{question}': {e}\")\n",
        "                    ground_truth_string = f\"ERROR executing ground truth query: {e}\"\n",
        "                    # Still include the question in the evaluation dataset, but with an error ground truth\n",
        "\n",
        "                # Simulate the Mistral model's text-to-sql process\n",
        "                model_answer, generated_sql, _ = text_to_sql_mistral(question, schema)\n",
        "\n",
        "                mistral_results.append({\n",
        "                    \"question\": question,\n",
        "                    \"answer\": model_answer,\n",
        "                    \"ground_truth\": ground_truth_string,\n",
        "                    \"contexts\": [f\"Generated SQL: {generated_sql}\"] # Using generated SQL as context\n",
        "                })\n",
        "\n",
        "            mistral_eval_dataset = Dataset.from_list(mistral_results)\n",
        "            print(\"--- Mistral Evaluation Dataset (with generated answers and dynamic ground truths) ---\")\n",
        "            print(f\"Dataset size: {len(mistral_eval_dataset)}\")\n",
        "            if len(mistral_eval_dataset) > 0:\n",
        "                print(\"First item:\")\n",
        "                print(mistral_eval_dataset[0])\n",
        "            else:\n",
        "                print(\"No evaluation data generated for Mistral. Check for errors during simulation.\")\n",
        "else:\n",
        "    print(\"Dependencies (df, pysqldf, text_to_sql_mistral) not available. Cannot prepare Mistral evaluation dataset.\")"
      ],
      "metadata": {
        "id": "b13J52S_ebRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a411862-a891-47ac-f71d-e5baac763fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulating Mistral SQL queries for the same 30 questions...\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE service = 'dns' AND proto = 'UDP';\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE dst_port < 1024 AND conn_state != 'normal';\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE src_port = dst_port;\n",
            "Generated SQL: SELECT dst_port, COUNT(*) as frequency\n",
            "FROM df\n",
            "GROUP BY dst_port\n",
            "ORDER BY frequency DESC\n",
            "LIMIT 10;\n",
            "Generated SQL: SELECT COUNT(*)\n",
            "FROM df\n",
            "WHERE duration < 0.001 AND src_pkts > 10;\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE duration = 0 AND (src_bytes = 0 AND dst_bytes = 0);\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE duration > 100 AND conn_state IN ('EST');\n",
            "Generated SQL: SELECT `service`, COUNT(`service`) as count\n",
            "FROM df\n",
            "WHERE `label` = 1\n",
            "GROUP BY `service`\n",
            "ORDER BY count DESC\n",
            "LIMIT 5;\n",
            "Generated SQL: SELECT AVG(duration) FROM df WHERE conn_state = 'SYN';\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE bytes = 0 AND duration > 0;\n",
            "Error executing SQL: (sqlite3.OperationalError) no such column: bytes\n",
            "[SQL: SELECT COUNT(*) FROM df WHERE bytes = 0 AND duration > 0;]\n",
            "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE src_ip = '192.168.1.100' AND label = 1;\n",
            "Generated SQL: SELECT DISTINCT proto FROM df WHERE label = 'injection';\n",
            "Generated SQL: SELECT src_ip, dst_ip FROM df WHERE type = 'injection';\n",
            "Generated SQL: SELECT src_ip, COUNT(*) as num_connections\n",
            " FROM df\n",
            " WHERE src_bytes = 0 AND type != 'normal';\n",
            " Group by src_ip;\n",
            "Error executing SQL: (sqlite3.ProgrammingError) You can only execute one statement at a time.\n",
            "[SQL: SELECT src_ip, COUNT(*) as num_connections\n",
            " FROM df\n",
            " WHERE src_bytes = 0 AND type != 'normal';\n",
            " Group by src_ip;]\n",
            "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
            "Generated SQL: SELECT AVG(duration) FROM df WHERE label = 'dos';\n",
            "Generated SQL: SELECT AVG(CASE WHEN label = 'normal' THEN (src_bytes + dst_bytes) ELSE 0 END) AS avg_normal,\n",
            "       AVG(CASE WHEN label = 'ddos' THEN (src_bytes + dst_bytes) ELSE 0 END) AS avg_ddos\n",
            "FROM df;\n",
            "Generated SQL: SELECT AVG(dst_bytes + missed_bytes) FROM df WHERE conn_state = 'RST';\n",
            "Generated SQL: SELECT AVG(src_pkts) FROM df WHERE dst_port = 22;\n",
            "Generated SQL: SELECT `conn_state`, COUNT(*)\n",
            "  FROM `df`\n",
            "  WHERE `type` = 'normal';\n",
            "Error executing SQL: (sqlite3.OperationalError) no such table: df\n",
            "[SQL: SELECT `conn_state`, COUNT(*)\n",
            "  FROM `df`\n",
            "  WHERE `type` = 'normal';]\n",
            "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
            "Generated SQL: SELECT MIN(duration) FROM df WHERE conn_state = 'ESTABLISHED' AND label = 'normal';\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE type != 'normal';\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE conn_state = 'S0';\n",
            "Generated SQL: SELECT DISTINCT conn_state FROM df WHERE label = 'ddos';\n",
            "Generated SQL: SELECT DISTINCT type, proto FROM df;\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE label = 'ddos';\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE dst_port < 1000 AND conn_state = 'REJ';\n",
            "Generated SQL: SELECT type FROM df WHERE dst_ip IN (255.255.255.255, '224.', '225.', '226.', '239.');\n",
            "Error executing SQL: (sqlite3.OperationalError) near \".255\": syntax error\n",
            "[SQL: SELECT type FROM df WHERE dst_ip IN (255.255.255.255, '224.', '225.', '226.', '239.');]\n",
            "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE conn_state = 'ddos' AND duration > 10;\n",
            "Generated SQL: SELECT COUNT(*) FROM df WHERE proto = 'TCP' AND (src_bytes = 0 OR dst_bytes = 0);\n",
            "Generated SQL: SELECT src_ip, COUNT(*) as num_connections\n",
            "  FROM df\n",
            "  WHERE conn_state = 'scanning'\n",
            "  GROUP BY src_ip;\n",
            "--- Mistral Evaluation Dataset (with generated answers and dynamic ground truths) ---\n",
            "Dataset size: 30\n",
            "First item:\n",
            "{'question': \"Count connections where the 'service' is 'dns' and the 'proto' is 'UDP'.\", 'answer': ' COUNT(*)\\n        0', 'ground_truth': ' COUNT(*)\\n        0', 'contexts': [\"Generated SQL: SELECT COUNT(*) FROM df WHERE service = 'dns' AND proto = 'UDP';\"]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Cell 8: Run and Display Ragas Score for SQL Mode (Segolily-Cybersecurity LLM)**"
      ],
      "metadata": {
        "id": "i3SSgJG9iicu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-google-genai\n",
        "\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import answer_correctness\n",
        "from ragas.metrics import faithfulness, context_precision, answer_relevancy\n",
        "# from langchain_openai import ChatOpenAI # Import the ChatOpenAI class - REMOVE THIS LINE\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI # Import the Google Gemini class\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings # Import Google Embeddings\n",
        "import os # Import os to access environment variables\n",
        "from google.colab import userdata # Import userdata to get secrets\n",
        "\n",
        "# Assuming your Google API key secret is named 'GOOGLE_API_KEY' in the Colab Secrets sidebar\n",
        "# Replace 'GOOGLE_API_KEY' if you used a different name for your secret\n",
        "google_api_key = None\n",
        "try:\n",
        "    google_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    # Set the environment variable that langchain/ragas expects\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
        "    print(\"Google API key loaded from Colab Secrets and set as GOOGLE_API_KEY environment variable.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Error: 'GOOGLE_API_KEY' not found in Colab Secrets.\")\n",
        "    print(\"Please add your Google API key to the Colab Secrets sidebar with the name 'GOOGLE_API_KEY'.\")\n",
        "    # You might want to stop execution here if the key is not found\n",
        "    # raise ValueError(\"'GOOGLE_API_KEY' secret not found.\")\n",
        "\n",
        "# Temporarily print masked key for verification (REMOVE THIS LINE LATER!)\n",
        "# Be careful not to print the whole key!\n",
        "if google_api_key:\n",
        "    print(f\"Verification: GOOGLE_API_KEY starts with {google_api_key[:5]}..., length {len(google_api_key)}\")\n",
        "else:\n",
        "     print(\"Verification: GOOGLE_API_KEY environment variable is not set.\")\n",
        "\n",
        "# Initialize the LLM Ragas will use for metrics, pointed at Google Gemini\n",
        "# Choose an appropriate Gemini model name (e.g., 'gemini-pro')\n",
        "ragas_eval_llm = None # Initialize to None\n",
        "ragas_eval_embeddings = None # Initialize embeddings to None\n",
        "\n",
        "if google_api_key:\n",
        "    print(\"Successfully retrieved Google API key. Initializing Gemini LLM and Embeddings.\")\n",
        "    ragas_eval_llm = ChatGoogleGenerativeAI(\n",
        "        model=\"models/gemini-1.5-pro\", # <--- Use a valid Google Gemini chat model name\n",
        "        temperature=0,\n",
        "        # Langchain's Google integration usually picks up GOOGLE_API_KEY from env,\n",
        "        # but you can pass it explicitly if needed: google_api_key=google_api_key\n",
        "    )\n",
        "    ragas_eval_embeddings = GoogleGenerativeAIEmbeddings(\n",
        "         model=\"models/text-embedding-004\" # <--- Use a valid Google Embeddings model name\n",
        "         # You might need to explicitly pass google_api_key here if the env variable isn't picked up\n",
        "         # google_api_key=google_api_key\n",
        "    )\n",
        "\n",
        "# For Text-to-SQL, the most important metric is answer_correctness.\n",
        "# It checks if the final answer string generated by our process matches the ground truth.\n",
        "# Ensure ragas_eval_llm and ragas_eval_embeddings are defined before calling evaluate\n",
        "if ragas_eval_llm and ragas_eval_embeddings:\n",
        "    print(\"\\nStarting Ragas evaluation with Gemini LLM and Embeddings...\")\n",
        "    segolily_sql_score = evaluate(\n",
        "        sql_eval_dataset,\n",
        "        metrics=[faithfulness, context_precision, answer_relevancy, answer_correctness],\n",
        "        # Pass the Langchain ChatGoogleGenerativeAI instance for evaluation\n",
        "        llm=ragas_eval_llm,\n",
        "        # Pass the Google Embeddings instance\n",
        "        embeddings=ragas_eval_embeddings,\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Segolily-Cybersecurity LLM RAGAS Score for SQL Data Query Mode ---\")\n",
        "    print(segolily_sql_score)\n",
        "    #print(f\"Overall Score: {segolily_sql_score['overall_score']:.4f}\")\n",
        "    #print(f\"Faithfulness: {segolily_sql_score['faithfulness']:.4f}\")\n",
        "    #print(f\"Context Precision: {segolily_sql_score['context_precision']}\")\n",
        "    #print(f\"Answer Relevancy: {segolily_sql_score['answer_relevancy']:.4f}\")\n",
        "    #print(f\"Answer Correctness: {segolily_sql_score['answer_correctness']:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nRagas evaluation LLM or Embeddings were not initialized due to missing Google API key.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mGoogle API key loaded from Colab Secrets and set as GOOGLE_API_KEY environment variable.\n",
            "Verification: GOOGLE_API_KEY starts with AIzaS..., length 39\n",
            "Successfully retrieved Google API key. Initializing Gemini LLM and Embeddings.\n",
            "\n",
            "Starting Ragas evaluation with Gemini LLM and Embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41ee33f36ce3430fa6fc48cd7e40e042"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Segolily-Cybersecurity LLM RAGAS Score for SQL Data Query Mode ---\n",
            "{'faithfulness': 0.0778, 'context_precision': 0.7333, 'answer_relevancy': 0.4236, 'answer_correctness': 0.1994}\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "Hr666dCLiicu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "41ee33f36ce3430fa6fc48cd7e40e042",
            "0864a1e234be422a94763c78d7b48255",
            "7bcd8d0a02414607b445757d80e2f938",
            "383c6683005d41579734a14ad61a01e7",
            "1e7aca78b34f47ba93252d22c2f67d17",
            "187bd8591d19458c9d8f68794b3e66c6",
            "d219e65896f742b6bd3e6db995f77af7",
            "34241b8d35ef4e538092abd30730dae5",
            "bb8f0bd281d64c7399e5a64b097852a9",
            "a44546a484954d1192640fa9e12b876f",
            "2031da8c5da64edab3d6020fccb26e0d"
          ]
        },
        "outputId": "1a9d3b0e-e72a-4c84-e5a6-e287bb09f6dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 9:Run and Display Ragas Score for SQL Mode (Mistral LLM)**"
      ],
      "metadata": {
        "id": "5bn8-_tJdgsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-google-genai\n",
        "\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import answer_correctness\n",
        "# from langchain_openai import ChatOpenAI # Import the ChatOpenAI class - REMOVE THIS LINE\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI # Import the Google Gemini class\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings # Import Google Embeddings\n",
        "import os # Import os to access environment variables\n",
        "from google.colab import userdata # Import userdata to get secrets\n",
        "\n",
        "# Assuming your Google API key secret is named 'GOOGLE_API_KEY' in the Colab Secrets sidebar\n",
        "# Replace 'GOOGLE_API_KEY' if you used a different name for your secret\n",
        "google_api_key = None\n",
        "try:\n",
        "    google_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    # Set the environment variable that langchain/ragas expects\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
        "    print(\"Google API key loaded from Colab Secrets and set as GOOGLE_API_KEY environment variable.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Error: 'GOOGLE_API_KEY' not found in Colab Secrets.\")\n",
        "    print(\"Please add your Google API key to the Colab Secrets sidebar with the name 'GOOGLE_API_KEY'.\")\n",
        "    # You might want to stop execution here if the key is not found\n",
        "    # raise ValueError(\"'GOOGLE_API_KEY' secret not found.\")\n",
        "\n",
        "# Temporarily print masked key for verification (REMOVE THIS LINE LATER!)\n",
        "# Be careful not to print the whole key!\n",
        "if google_api_key:\n",
        "    print(f\"Verification: GOOGLE_API_KEY starts with {google_api_key[:5]}..., length {len(google_api_key)}\")\n",
        "else:\n",
        "     print(\"Verification: GOOGLE_API_KEY environment variable is not set.\")\n",
        "\n",
        "# Initialize the LLM Ragas will use for metrics, pointed at Google Gemini\n",
        "# Choose an appropriate Gemini model name (e.g., 'gemini-pro')\n",
        "ragas_eval_llm = None # Initialize to None\n",
        "ragas_eval_embeddings = None # Initialize embeddings to None\n",
        "\n",
        "if google_api_key:\n",
        "    print(\"Successfully retrieved Google API key. Initializing Gemini LLM and Embeddings.\")\n",
        "    ragas_eval_llm = ChatGoogleGenerativeAI(\n",
        "        model=\"models/gemini-1.5-pro\", # <--- Use a valid Google Gemini chat model name\n",
        "        temperature=0,\n",
        "        # Langchain's Google integration usually picks up GOOGLE_API_KEY from env,\n",
        "        # but you can pass it explicitly if needed: google_api_key=google_api_key\n",
        "    )\n",
        "    ragas_eval_embeddings = GoogleGenerativeAIEmbeddings(\n",
        "         model=\"models/text-embedding-004\" # <--- Use a valid Google Embeddings model name\n",
        "         # You might need to explicitly pass google_api_key here if the env variable isn't picked up\n",
        "         # google_api_key=google_api_key\n",
        "    )\n",
        "\n",
        "# For Text-to-SQL, the most important metric is answer_correctness.\n",
        "# It checks if the final answer string generated by our process matches the ground truth.\n",
        "# Ensure ragas_eval_llm and ragas_eval_embeddings are defined before calling evaluate\n",
        "if ragas_eval_llm and ragas_eval_embeddings:\n",
        "    print(\"\\nStarting Ragas evaluation with Gemini LLM and Embeddings...\")\n",
        "    mistral_sql_score = evaluate(\n",
        "        mistral_eval_dataset,\n",
        "        metrics=[faithfulness, context_precision, answer_relevancy, answer_correctness],\n",
        "        # Pass the Langchain ChatGoogleGenerativeAI instance for evaluation\n",
        "        llm=ragas_eval_llm,\n",
        "        # Pass the Google Embeddings instance\n",
        "        embeddings=ragas_eval_embeddings,\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Mistral LLM RAGAS Score for SQL Data Query Mode ---\")\n",
        "    print(mistral_sql_score)\n",
        "else:\n",
        "    print(\"\\nRagas evaluation LLM or Embeddings were not initialized due to missing Google API key.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "99f63c4768af4d19992a633c77adfd07",
            "c7e57ee618fa4990b123d48db0f1e730",
            "c7f65d7db4f7440f9ee3d1ac0eb33bd9",
            "83e6e1c82f7946cabe545c23de3958a3",
            "ceddc4110e9143bd8171b0e5e384c50a",
            "c53b00319e6845d4a677bb97cf41c179",
            "2c69b426e25948d6837b31835256e124",
            "945bc18778fb44d18074f63041cc4da7",
            "ad8f6f02bbe54160b0eaddbbdd469202",
            "97d588524e244dd4b905a93916d19103",
            "062539772bfa46049241501d5ee1f825"
          ]
        },
        "id": "nJCmH2M7fPpL",
        "outputId": "245c4e9c-c2dc-491e-befd-28bdc8f93567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google API key loaded from Colab Secrets and set as GOOGLE_API_KEY environment variable.\n",
            "Verification: GOOGLE_API_KEY starts with AIzaS..., length 39\n",
            "Successfully retrieved Google API key. Initializing Gemini LLM and Embeddings.\n",
            "\n",
            "Starting Ragas evaluation with Gemini LLM and Embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99f63c4768af4d19992a633c77adfd07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Mistral LLM RAGAS Score for SQL Data Query Mode ---\n",
            "{'faithfulness': 0.1017, 'context_precision': 0.8333, 'answer_relevancy': 0.4322, 'answer_correctness': 0.5113}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 10:  Compare Scores (Segolily Cybersecurity LLM vs Mistral LLM)**"
      ],
      "metadata": {
        "id": "YAk9FKn5fZNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import altair as alt\n",
        "from IPython.display import display\n",
        "\n",
        "# Your Ragas scores\n",
        "segolily_sql_score = {'faithfulness': 0.0528, 'context_precision': 0.7667, 'answer_relevancy': 0.4411, 'answer_correctness': 0.2300}\n",
        "mistral_sql_score = {'faithfulness': 0.1389, 'context_precision': 0.8667, 'answer_relevancy': 0.4351, 'answer_correctness': 0.5336}\n",
        "\n",
        "# --- Data Preparation (common for all charts) ---\n",
        "data = []\n",
        "for metric, score in segolily_sql_score.items():\n",
        "    # Update model name\n",
        "    data.append({'Metric': metric, 'Score': score, 'Model': 'Lily-Cybersecurity-7B'})\n",
        "for metric, score in mistral_sql_score.items():\n",
        "    # Update model name\n",
        "    data.append({'Metric': metric, 'Score': score, 'Model': 'Mistral-7b'})\n",
        "\n",
        "df_scores = pd.DataFrame(data)\n",
        "\n",
        "print(\"--- Faceted Bar Chart ---\")\n",
        "# --- Faceted Bar Chart ---\n",
        "chart_faceted_bar = alt.Chart(df_scores).mark_bar().encode(\n",
        "    x=alt.X('Model:N', axis=None), # Show model on x, but hide axis label\n",
        "    # Set y-axis domain to [0, 1] within the scale parameter\n",
        "    y=alt.Y('Score:Q', title='Ragas Score', scale=alt.Scale(domain=[0, 1])),\n",
        "    color=alt.Color('Model:N'),\n",
        "    column=alt.Column(\n",
        "        'Metric:N',\n",
        "        header=alt.Header(\n",
        "            titleOrient=\"bottom\",  # Title orientation\n",
        "            labelOrient=\"left\",    # Label orientation - changed to 'left' for vertical\n",
        "            labelAngle=-90         # Angle of the label text (-90 for vertical)\n",
        "        ),\n",
        "        title='Ragas Metric'\n",
        "    ), # Separate bars by metric\n",
        "    tooltip=['Metric', 'Model', 'Score']\n",
        ").properties(\n",
        "    title='Ragas Scores by Metric'\n",
        ")\n",
        "display(chart_faceted_bar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "q86KwsPWfYI9",
        "outputId": "faceaf06-72df-49f5-db52-528f6a0cb025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Faceted Bar Chart ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-5bf466cb4a1f4b7fbe812be7dafd379e.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-5bf466cb4a1f4b7fbe812be7dafd379e.vega-embed details,\n",
              "  #altair-viz-5bf466cb4a1f4b7fbe812be7dafd379e.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-5bf466cb4a1f4b7fbe812be7dafd379e\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-5bf466cb4a1f4b7fbe812be7dafd379e\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-5bf466cb4a1f4b7fbe812be7dafd379e\");\n",
              "    }\n",
              "\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      let deps = [\"vega-embed\"];\n",
              "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-a7b7f3935289a337e7697eeadbb752cc\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"Model\", \"type\": \"nominal\"}, \"column\": {\"field\": \"Metric\", \"header\": {\"labelAngle\": -90, \"labelOrient\": \"left\", \"titleOrient\": \"bottom\"}, \"title\": \"Ragas Metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Metric\", \"type\": \"nominal\"}, {\"field\": \"Model\", \"type\": \"nominal\"}, {\"field\": \"Score\", \"type\": \"quantitative\"}], \"x\": {\"axis\": null, \"field\": \"Model\", \"type\": \"nominal\"}, \"y\": {\"field\": \"Score\", \"scale\": {\"domain\": [0, 1]}, \"title\": \"Ragas Score\", \"type\": \"quantitative\"}}, \"title\": \"Ragas Scores by Metric\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-a7b7f3935289a337e7697eeadbb752cc\": [{\"Metric\": \"faithfulness\", \"Score\": 0.0528, \"Model\": \"Lily-Cybersecurity-7B\"}, {\"Metric\": \"context_precision\", \"Score\": 0.7667, \"Model\": \"Lily-Cybersecurity-7B\"}, {\"Metric\": \"answer_relevancy\", \"Score\": 0.4411, \"Model\": \"Lily-Cybersecurity-7B\"}, {\"Metric\": \"answer_correctness\", \"Score\": 0.23, \"Model\": \"Lily-Cybersecurity-7B\"}, {\"Metric\": \"faithfulness\", \"Score\": 0.1389, \"Model\": \"Mistral-7b\"}, {\"Metric\": \"context_precision\", \"Score\": 0.8667, \"Model\": \"Mistral-7b\"}, {\"Metric\": \"answer_relevancy\", \"Score\": 0.4351, \"Model\": \"Mistral-7b\"}, {\"Metric\": \"answer_correctness\", \"Score\": 0.5336, \"Model\": \"Mistral-7b\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Part 3: AI Security Analysis (RAG) Mode Evaluation**\n",
        "\n",
        "#### **Cell 8: Define and Simulate the RAG Mode Process**"
      ],
      "metadata": {
        "id": "1edgqgGkiicu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question_from_context(question, context):\n",
        "    \"\"\"\n",
        "    Simulates the final stage of the bizbot's RAG process.\n",
        "    Answers a question based ONLY on the provided text context.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are a precise cybersecurity analyst AI. Your task is to answer the question based *only* on the data context provided below. Do not use any external knowledge.\n",
        "\n",
        "**Data Context:**\n",
        "{context}\n",
        "\n",
        "**Question:**\n",
        "{question}\n",
        "\n",
        "**Answer:**\n",
        "\"\"\"\n",
        "    response = hf_pipeline(prompt)[0]['generated_text']\n",
        "    # Clean up the response to get only the final answer\n",
        "    answer = response.split(\"Answer:\")[1].strip()\n",
        "    return answer"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "BPX4Wa9Niicv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Cell 9: Prepare RAG Evaluation Dataset**"
      ],
      "metadata": {
        "id": "uj9nSysgiicv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will create an evaluation set from the actual data.\n",
        "# Each row of data will be a \"context\".\n",
        "# Corrected column name for attack type filtering from 'label' to 'type'\n",
        "# Assuming 'Benign' attack name is lowercase 'benign' in 'type' column\n",
        "attack_df = df[df['type'] != 'benign'].sample(n=10, random_state=42)\n",
        "\n",
        "rag_eval_list = []\n",
        "\n",
        "for _, row in attack_df.iterrows():\n",
        "    # The context is the specific row of data, simulating what a retriever would find\n",
        "    context = row.to_string()\n",
        "    # The question is about a specific piece of information in that context\n",
        "    question = \"Based on the provided data context, what is the specific attack type?\" # Changed question to reflect 'type'\n",
        "    # The ground truth is the actual value from the 'type' column (corrected)\n",
        "    # Ensure ground_truth is a string\n",
        "    ground_truth = str(row['type']) # Corrected column name\n",
        "\n",
        "    # Simulate the bizbot process to get the model's answer\n",
        "    model_answer = answer_question_from_context(question, context)\n",
        "\n",
        "    rag_eval_list.append({\n",
        "        \"question\": question,\n",
        "        \"answer\": model_answer,\n",
        "        \"contexts\": [context],\n",
        "        \"ground_truth\": ground_truth # Now guaranteed to be a string\n",
        "    })\n",
        "\n",
        "rag_eval_dataset = Dataset.from_list(rag_eval_list)\n",
        "print(\"--- RAG Evaluation Dataset (with generated answers) ---\")\n",
        "if len(rag_eval_dataset) > 0:\n",
        "    print(rag_eval_dataset[0])\n",
        "else:\n",
        "    print(\"RAG evaluation dataset is empty.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- RAG Evaluation Dataset (with generated answers) ---\n",
            "{'question': 'Based on the provided data context, what is the specific attack label?', 'answer': \"**\\nThe specific attack label is '1'.\", 'contexts': ['frame_time                    2021 21:35:21.336811000 \\nip_src_host                              192.168.0.128\\nip_dst_host                              192.168.0.170\\narp_dst_proto_ipv4                                   0\\narp_opcode                                         0.0\\narp_hw_size                                        0.0\\narp_src_proto_ipv4                                   0\\nicmp_checksum                                      0.0\\nicmp_seq_le                                        0.0\\nicmp_transmit_timestamp                            0.0\\nicmp_unused                                        0.0\\nhttp_file_data                                     0.0\\nhttp_content_length                                0.0\\nhttp_request_uri_query                               0\\nhttp_request_method                                  0\\nhttp_referer                                       0.0\\nhttp_request_full_uri                                0\\nhttp_request_version                                 0\\nhttp_response                                      0.0\\nhttp_tls_port                                      0.0\\ntcp_ack                                          354.0\\ntcp_ack_raw                               2504429313.0\\ntcp_checksum                                   64954.0\\ntcp_connection_fin                                 1.0\\ntcp_connection_rst                                 0.0\\ntcp_connection_syn                                 0.0\\ntcp_connection_synack                              0.0\\ntcp_dstport                                    37160.0\\ntcp_flags                                         17.0\\ntcp_flags_ack                                      1.0\\ntcp_len                                            0.0\\ntcp_options                   0101080a9eac04e29b1e7239\\ntcp_payload                                          0\\ntcp_seq                                          478.0\\ntcp_srcport                                       80.0\\nudp_port                                           0.0\\nudp_stream                                         0.0\\nudp_time_delta                                     0.0\\ndns_qry_name                                       0.0\\ndns_qry_name_len                                   0.0\\ndns_qry_qu                                         0.0\\ndns_qry_type                                       0.0\\ndns_retransmission                                 0.0\\ndns_retransmit_request                             0.0\\ndns_retransmit_request_in                          0.0\\nmqtt_conack_flags                                  0.0\\nmqtt_conflag_cleansess                             0.0\\nmqtt_conflags                                      0.0\\nmqtt_hdrflags                                      0.0\\nmqtt_len                                           0.0\\nmqtt_msg_decoded_as                                0.0\\nmqtt_msg                                           0.0\\nmqtt_msgtype                                       0.0\\nmqtt_proto_len                                     0.0\\nmqtt_protoname                                     0.0\\nmqtt_topic                                         0.0\\nmqtt_topic_len                                     0.0\\nmqtt_ver                                           0.0\\nmbtcp_len                                          0.0\\nmbtcp_trans_id                                     0.0\\nmbtcp_unit_id                                      0.0\\nAttack_label                                         1\\nAttack_type                              SQL_injection'], 'ground_truth': '1'}\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "FQk8j_giiicv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b694783-0f44-4cfc-b886-be9c6ed62baa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Cell 10: Run and Display Ragas Score for RAG Mode**"
      ],
      "metadata": {
        "id": "MUYQo43liicw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas.metrics import faithfulness\n",
        "from ragas.metrics import answer_correctness # Ensure this is imported as well\n",
        "import os # Import os to access environment variables\n",
        "from google.colab import userdata # Import userdata to get secrets\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI # Import the Google Gemini class\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings # Import Google Embeddings\n",
        "\n",
        "# For RAG, we evaluate both correctness and faithfulness.\n",
        "# - answer_correctness: Does the answer match the ground_truth label?\n",
        "# - faithfulness: Does the answer come directly from the provided context?\n",
        "# Ensure ragas_eval_llm and ragas_eval_embeddings are defined from Cell 7\n",
        "\n",
        "# Re-checking if the key was loaded and the models were initialized\n",
        "google_api_key = None\n",
        "try:\n",
        "    # Make sure this secret name matches the one you used in Colab Secrets\n",
        "    # And that the key corresponds to your PRO subscription project\n",
        "    google_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
        "    print(\"Google API key loaded from Colab Secrets and set as GOOGLE_API_KEY environment variable.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Error: 'GOOGLE_API_KEY' not found in Colab Secrets.\")\n",
        "    print(\"Please add your Google API key to the Colab Secrets sidebar with the name 'GOOGLE_API_KEY'.\")\n",
        "\n",
        "ragas_eval_llm = None\n",
        "ragas_eval_embeddings = None\n",
        "\n",
        "if google_api_key:\n",
        "    print(\"Successfully retrieved Google API key. Initializing Gemini LLM and Embeddings.\")\n",
        "    try:\n",
        "        ragas_eval_llm = ChatGoogleGenerativeAI(\n",
        "            model=\"models/gemini-2.0-flash\", # <--- Use a valid Google Gemini chat model name\n",
        "            temperature=0,\n",
        "            # Langchain's Google integration usually picks up GOOGLE_API_KEY from env\n",
        "            # api_key=google_api_key # Explicitly pass key just in case env isn't picked up\n",
        "        )\n",
        "        ragas_eval_embeddings = GoogleGenerativeAIEmbeddings(\n",
        "             model=\"models/text-embedding-004\" # <--- Use a valid Google Embeddings model name\n",
        "             # api_key=google_api_key # Explicitly pass key just in case env isn't picked up\n",
        "        )\n",
        "        print(\"Gemini LLM and Embeddings initialized.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Google models: {e}\")\n",
        "        print(\"Please check your API key and ensure the model name is correct and accessible.\")\n",
        "\n",
        "\n",
        "if 'ragas_eval_llm' in locals() and ragas_eval_llm and 'ragas_eval_embeddings' in locals() and ragas_eval_embeddings:\n",
        "    print(\"\\nStarting Ragas evaluation for RAG mode with Gemini LLM and Embeddings...\")\n",
        "    try:\n",
        "        rag_score = evaluate(\n",
        "            rag_eval_dataset,\n",
        "            metrics=[answer_correctness, faithfulness],\n",
        "            llm=ragas_eval_llm,\n",
        "            embeddings=ragas_eval_embeddings,\n",
        "            # Reduce the batch size further\n",
        "            batch_size=1 # Try batch size 1 to minimize simultaneous requests\n",
        "        )\n",
        "\n",
        "        print(\"\\n--- RAGAS Score for AI Security Analysis (RAG) Mode ---\")\n",
        "        print(rag_score)\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred during Ragas evaluation: {e}\")\n",
        "        print(\"This might still be a rate limit issue or another API error.\")\n",
        "        print(\"If you continue to see FreeTier quota errors despite having a Pro subscription,\")\n",
        "        print(\"please verify your Google Cloud project's billing and API quotas.\")\n",
        "\n",
        "else:\n",
        "     print(\"\\nRagas evaluation LLM or Embeddings were not initialized. Cannot evaluate RAG mode.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google API key loaded from Colab Secrets and set as GOOGLE_API_KEY environment variable.\n",
            "Successfully retrieved Google API key. Initializing Gemini LLM and Embeddings.\n",
            "Gemini LLM and Embeddings initialized.\n",
            "\n",
            "Starting Ragas evaluation for RAG mode with Gemini LLM and Embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0414eb4db4994ed2a529f320dfd37a20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batch 1/20:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf55f8984c2a413fb4a0ba490277305d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 59\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 56\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 54\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 51\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 49\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 45\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 39\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 44\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 41\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 39\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 36\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 32\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RAGAS Score for AI Security Analysis (RAG) Mode ---\n",
            "{'answer_correctness': 0.9390, 'faithfulness': 1.0000}\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "1GQydZWaiicw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0414eb4db4994ed2a529f320dfd37a20",
            "97eb42de8b69424daaab954cf47dd171",
            "4dafa4a636ef4415ae0dfff5fd0d555e",
            "4a2c127a53044420802a5d533827732f",
            "a6e4c6e2beec41e8bc8af42dcdaabccd",
            "f6063bf654aa4ff5bb75dfb4c2d2a579",
            "97ccea12c1474229bf3cfddffdf72318",
            "404cd555137f457eb48c60c1442a3c42",
            "5c1f383e85764f03996c631d89480949",
            "abcdf063706348dfa0d1be7d820a92dd",
            "bfc99166413e49318fa87d7487de3006",
            "bf55f8984c2a413fb4a0ba490277305d",
            "702ca69a02bf4677bfd8a54b814ccf87",
            "11822ee8e7d6403092be2627565d2e7e",
            "fa9e2efbf16d48e3a90ff9b4689ef247",
            "2b4b6c29ee8947779653621fa6caf58a",
            "57d309ed99f14a069fb33cd86773ec7a",
            "4601dd75dfce4f40a77df852733eba58",
            "fdc0052d27b943a58c0bdd788415206a",
            "10e2f21399464a66962bfe81ae8f72f5",
            "41319c31fdd949ccae62f9da346b5ec2",
            "2aefffb75c10402fbc4cb11a7a3160f8"
          ]
        },
        "outputId": "c823bcf2-c619-4129-de08-ea5f2bea3a8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4: Visualize Ragas Results**"
      ],
      "metadata": {
        "id": "Gc-nquWvBItR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure sql_score and rag_score are available from previous cells\n",
        "if 'sql_score' in globals() and 'rag_score' in globals():\n",
        "    print(\"Visualizing Ragas scores...\")\n",
        "\n",
        "    # Convert the scores to dictionaries for easier handling\n",
        "    sql_scores_dict = sql_score.to_pandas().iloc[0].to_dict() # sql_score is likely a Dataset, convert to pandas\n",
        "    rag_scores_dict = rag_score.to_pandas().iloc[0].to_dict()\n",
        "\n",
        "    # Prepare data for plotting\n",
        "    modes = ['SQL Data Query', 'AI Security Analysis (RAG)']\n",
        "    metrics = ['answer_correctness', 'faithfulness'] # Only these two metrics are common/calculated\n",
        "\n",
        "    # Extract scores, handling metrics that might not be present in both\n",
        "    sql_correctness = sql_scores_dict.get('answer_correctness', 0) # Default to 0 if not found\n",
        "    sql_faithfulness = sql_scores_dict.get('faithfulness', 0) # Faithfulness wasn't calculated for SQL, expect 0\n",
        "\n",
        "    rag_correctness = rag_scores_dict.get('answer_correctness', 0)\n",
        "    rag_faithfulness = rag_scores_dict.get('faithfulness', 0)\n",
        "\n",
        "\n",
        "    correctness_scores = [sql_correctness, rag_correctness]\n",
        "    faithfulness_scores = [sql_faithfulness, rag_faithfulness]\n",
        "\n",
        "\n",
        "    # Create bar chart\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    bar_width = 0.35\n",
        "    index = range(len(modes))\n",
        "\n",
        "    bar1 = ax.bar(index, correctness_scores, bar_width, label='Answer Correctness')\n",
        "    bar2 = ax.bar([i + bar_width for i in index], faithfulness_scores, bar_width, label='Faithfulness')\n",
        "\n",
        "    ax.set_xlabel('Analysis Mode')\n",
        "    ax.set_ylabel('Ragas Score')\n",
        "    ax.set_title('Comparison of Ragas Scores by Analysis Mode')\n",
        "    ax.set_xticks([i + bar_width / 2 for i in index])\n",
        "    ax.set_xticklabels(modes)\n",
        "    ax.set_ylim(0, 1.1) # Scores are between 0 and 1\n",
        "\n",
        "    # Add score values on top of the bars\n",
        "    def autolabel(bars):\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.3f}',\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "    autolabel(bar1)\n",
        "    autolabel(bar2)\n",
        "\n",
        "\n",
        "    ax.legend()\n",
        "    plt.grid(axis='y', linestyle='--')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Ragas scores (sql_score and rag_score) not found. Please run previous cells to calculate them.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "-AoM5W7HBQlf",
        "outputId": "edcf61cf-385c-4420-b7ba-b4875dfb2fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualizing Ragas scores...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"md-recitation\">\n",
        "  Sources\n",
        "  <ol>\n",
        "  <li><a href=\"https://huggingface.co/llava-hf/llava-v1.6-34b-hf/discussions/8\">https://huggingface.co/llava-hf/llava-v1.6-34b-hf/discussions/8</a></li>\n",
        "  <li><a href=\"https://github.com/Equipo45/hf-example\">https://github.com/Equipo45/hf-example</a></li>\n",
        "  </ol>\n",
        "</div>"
      ],
      "metadata": {
        "id": "MHLvAqNoiicw"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0414eb4db4994ed2a529f320dfd37a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97eb42de8b69424daaab954cf47dd171",
              "IPY_MODEL_4dafa4a636ef4415ae0dfff5fd0d555e",
              "IPY_MODEL_4a2c127a53044420802a5d533827732f"
            ],
            "layout": "IPY_MODEL_a6e4c6e2beec41e8bc8af42dcdaabccd"
          }
        },
        "97eb42de8b69424daaab954cf47dd171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6063bf654aa4ff5bb75dfb4c2d2a579",
            "placeholder": "​",
            "style": "IPY_MODEL_97ccea12c1474229bf3cfddffdf72318",
            "value": "Evaluating: 100%"
          }
        },
        "4dafa4a636ef4415ae0dfff5fd0d555e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_404cd555137f457eb48c60c1442a3c42",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c1f383e85764f03996c631d89480949",
            "value": 20
          }
        },
        "4a2c127a53044420802a5d533827732f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abcdf063706348dfa0d1be7d820a92dd",
            "placeholder": "​",
            "style": "IPY_MODEL_bfc99166413e49318fa87d7487de3006",
            "value": " 20/20 [01:49&lt;00:00,  5.06s/it]"
          }
        },
        "a6e4c6e2beec41e8bc8af42dcdaabccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6063bf654aa4ff5bb75dfb4c2d2a579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ccea12c1474229bf3cfddffdf72318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "404cd555137f457eb48c60c1442a3c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c1f383e85764f03996c631d89480949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abcdf063706348dfa0d1be7d820a92dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfc99166413e49318fa87d7487de3006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf55f8984c2a413fb4a0ba490277305d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_702ca69a02bf4677bfd8a54b814ccf87",
              "IPY_MODEL_11822ee8e7d6403092be2627565d2e7e",
              "IPY_MODEL_fa9e2efbf16d48e3a90ff9b4689ef247"
            ],
            "layout": "IPY_MODEL_2b4b6c29ee8947779653621fa6caf58a"
          }
        },
        "702ca69a02bf4677bfd8a54b814ccf87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57d309ed99f14a069fb33cd86773ec7a",
            "placeholder": "​",
            "style": "IPY_MODEL_4601dd75dfce4f40a77df852733eba58",
            "value": "Batch 20/20: 100%"
          }
        },
        "11822ee8e7d6403092be2627565d2e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdc0052d27b943a58c0bdd788415206a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10e2f21399464a66962bfe81ae8f72f5",
            "value": 1
          }
        },
        "fa9e2efbf16d48e3a90ff9b4689ef247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41319c31fdd949ccae62f9da346b5ec2",
            "placeholder": "​",
            "style": "IPY_MODEL_2aefffb75c10402fbc4cb11a7a3160f8",
            "value": " 1/1 [00:01&lt;00:00,  1.34s/it]"
          }
        },
        "2b4b6c29ee8947779653621fa6caf58a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "57d309ed99f14a069fb33cd86773ec7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4601dd75dfce4f40a77df852733eba58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdc0052d27b943a58c0bdd788415206a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10e2f21399464a66962bfe81ae8f72f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41319c31fdd949ccae62f9da346b5ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aefffb75c10402fbc4cb11a7a3160f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c053ff24b20a4aca9b51bba5b2f43e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e524c8cf87244ffaa1dc811572ef4dd",
              "IPY_MODEL_30bbe46bc9c74c01a92eff532ce01b4a",
              "IPY_MODEL_8826fe63e89645f79ed0892e84df6b41"
            ],
            "layout": "IPY_MODEL_42c9090cefca45cea571855536c2dfd9"
          }
        },
        "6e524c8cf87244ffaa1dc811572ef4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31b9aed3f791419c9a7d8b0e51e3c09e",
            "placeholder": "​",
            "style": "IPY_MODEL_497cacbfaac84b1ab5c07bce41330b63",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "30bbe46bc9c74c01a92eff532ce01b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d7394699494ec4a8c40d0dbb3e730c",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6393048a02a8421a8d7b36d13a8a9d15",
            "value": 6
          }
        },
        "8826fe63e89645f79ed0892e84df6b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8261d8aa782c4e069faf411086ed0598",
            "placeholder": "​",
            "style": "IPY_MODEL_b2a0053c05ea43c1b4b933d8dabf70f5",
            "value": " 6/6 [01:10&lt;00:00, 11.01s/it]"
          }
        },
        "42c9090cefca45cea571855536c2dfd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31b9aed3f791419c9a7d8b0e51e3c09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497cacbfaac84b1ab5c07bce41330b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8d7394699494ec4a8c40d0dbb3e730c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6393048a02a8421a8d7b36d13a8a9d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8261d8aa782c4e069faf411086ed0598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a0053c05ea43c1b4b933d8dabf70f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41ee33f36ce3430fa6fc48cd7e40e042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0864a1e234be422a94763c78d7b48255",
              "IPY_MODEL_7bcd8d0a02414607b445757d80e2f938",
              "IPY_MODEL_383c6683005d41579734a14ad61a01e7"
            ],
            "layout": "IPY_MODEL_1e7aca78b34f47ba93252d22c2f67d17"
          }
        },
        "0864a1e234be422a94763c78d7b48255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_187bd8591d19458c9d8f68794b3e66c6",
            "placeholder": "​",
            "style": "IPY_MODEL_d219e65896f742b6bd3e6db995f77af7",
            "value": "Evaluating: 100%"
          }
        },
        "7bcd8d0a02414607b445757d80e2f938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34241b8d35ef4e538092abd30730dae5",
            "max": 120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb8f0bd281d64c7399e5a64b097852a9",
            "value": 120
          }
        },
        "383c6683005d41579734a14ad61a01e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a44546a484954d1192640fa9e12b876f",
            "placeholder": "​",
            "style": "IPY_MODEL_2031da8c5da64edab3d6020fccb26e0d",
            "value": " 120/120 [02:58&lt;00:00, 17.73s/it]"
          }
        },
        "1e7aca78b34f47ba93252d22c2f67d17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "187bd8591d19458c9d8f68794b3e66c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d219e65896f742b6bd3e6db995f77af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34241b8d35ef4e538092abd30730dae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8f0bd281d64c7399e5a64b097852a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a44546a484954d1192640fa9e12b876f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2031da8c5da64edab3d6020fccb26e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99f63c4768af4d19992a633c77adfd07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7e57ee618fa4990b123d48db0f1e730",
              "IPY_MODEL_c7f65d7db4f7440f9ee3d1ac0eb33bd9",
              "IPY_MODEL_83e6e1c82f7946cabe545c23de3958a3"
            ],
            "layout": "IPY_MODEL_ceddc4110e9143bd8171b0e5e384c50a"
          }
        },
        "c7e57ee618fa4990b123d48db0f1e730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c53b00319e6845d4a677bb97cf41c179",
            "placeholder": "​",
            "style": "IPY_MODEL_2c69b426e25948d6837b31835256e124",
            "value": "Evaluating: 100%"
          }
        },
        "c7f65d7db4f7440f9ee3d1ac0eb33bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_945bc18778fb44d18074f63041cc4da7",
            "max": 120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad8f6f02bbe54160b0eaddbbdd469202",
            "value": 120
          }
        },
        "83e6e1c82f7946cabe545c23de3958a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97d588524e244dd4b905a93916d19103",
            "placeholder": "​",
            "style": "IPY_MODEL_062539772bfa46049241501d5ee1f825",
            "value": " 120/120 [01:01&lt;00:00,  1.10it/s]"
          }
        },
        "ceddc4110e9143bd8171b0e5e384c50a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c53b00319e6845d4a677bb97cf41c179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c69b426e25948d6837b31835256e124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "945bc18778fb44d18074f63041cc4da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8f6f02bbe54160b0eaddbbdd469202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97d588524e244dd4b905a93916d19103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "062539772bfa46049241501d5ee1f825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}